// TODO: this whole file.
// (that might also mean that datareader/datawriter cdr 
use std::{
  sync::{Arc, RwLock},
  time::Duration as StdDuration,
};

use io_uring::IoUring;
use crate::io_uring::discovery::discovery_db::DiscoveredVia;
use crate::TopicCache;
use crate::dds::ddsdata::DDSData;
use crate::SequenceNumber;
use crate::WriteOptions;
use crate::io_uring::network::UDPSender;

use crate::dds::{ReadError, ReadResult};
use crate::structure::cache_change::CacheChange;
use crate::with_key::DeserializedCacheChange;

use crate::rtps::message_receiver::MessageReceiverState;

#[allow(unused_imports)]
use log::{debug, error, info, trace, warn};
use mio_06::{Events, Poll, PollOpt, Ready};
//use mio_extras::{channel as mio_channel, timer::Timer};
use paste::paste; // token pasting macro

use crate::{
  dds::{
    participant::DomainParticipantWeak,
    qos::{
      policy::{
        Deadline, DestinationOrder, Durability, History, Liveliness, Ownership, Presentation,
        PresentationAccessScope, Reliability, TimeBasedFilter,
      },
      QosPolicies, QosPolicyBuilder,
    },
    readcondition::ReadCondition,
    result::{CreateError, CreateResult, WriteResult, WriteError},
    statusevents::{DomainParticipantStatusEvent, LostReason, StatusChannelSender},
  },
  discovery::{
    sedp_messages::{
      DiscoveredReaderData, DiscoveredTopicData, DiscoveredWriterData, Endpoint_GUID,
      ParticipantMessageData, ParticipantMessageDataKind,
    },
    spdp_participant_data::{Participant_GUID, SpdpDiscoveredParticipantData},
  },
  polling::{new_simple_timer, TimerPolicy},
  rtps::constant::*,
  serialization::{pl_cdr_adapters::*, CDRDeserializerAdapter, CDRSerializerAdapter},
  structure::{
    duration::Duration,
    entity::RTPSEntity,
    guid::{EntityId, GuidPrefix, GUID},
    time::Timestamp,
  },
  with_key::{DataReader, DataWriter, Sample, DataSample},
  DomainParticipant,
};

use crate::io_uring::discovery::discovery_db::DiscoveryDB;

// This module implements the control logic of the Discovery process.
//
// The built-in discovery consists of
// Simple Participant Discovery Protocol (SPDP), (RTPS spec v2.5
// Section "8.5.3 The Simple Participant Discovery Protocol") and
// Simple Endpoint Discovery Protocol (SEDP) (RTPS spec v2.5
// Section "8.5.4 The Simple Endpoint Discovery Protocol")
//
// Notes:
//
// SPDP is periodically broadcast from each DomainParticipant to announce presence to others.
// It is essentially stateless and best-effort. It also announces built-in endpoints.
// See module spdp_participant_data for details.
//
// SEDP is Reliable transfer of user-defined endpoints (Readers, Writers and Topics).
// Many DDS implementations do not communicate Topics at all, and seem to work just fine.
//
// "Participant Message" protocol is NOT the same as SPDP. See RTPS spec v2.5 Section
// "8.4.13 Writer Liveliness Protocol". It can be used as liveliness (hearbeat)
// signalling of individual Writers.
//
// "Participant Stateless Message" and "Participant Volatile Message" only appear
// in Secure RTPS. Please see the RTPS Security specification for explanation.
#[cfg(feature = "security")]
use crate::{
  discovery::secure_discovery::SecureDiscovery,
  security::{security_plugins::SecurityPluginsHandle, types::*},
};
#[cfg(not(feature = "security"))]
use crate::no_security::*;

#[derive(Clone, Eq, PartialEq, Ord, PartialOrd, Hash)]
pub enum DiscoveryCommand {
  StopDiscovery,
  AddLocalWriter {
    guid: GUID,
  },
  AddLocalReader {
    guid: GUID,
  },
  AddTopic {
    topic_name: String,
  },
  RemoveLocalWriter {
    guid: GUID,
  },
  RemoveLocalReader {
    guid: GUID,
  },
  ManualAssertLiveliness,
  AssertTopicLiveliness {
    writer_guid: GUID,
    manual_assertion: bool,
  },

  #[cfg(feature = "security")]
  StartKeyExchangeWithRemoteParticipant {
    participant_guid_prefix: GuidPrefix,
  },

  #[cfg(feature = "security")]
  StartKeyExchangeWithRemoteEndpoint {
    local_endpoint_guid: GUID,
    remote_endpoint_guid: GUID,
  },
}

pub struct LivelinessState {
  last_auto_update: Timestamp,
  manual_participant_liveness_refresh_requested: bool,
}

impl LivelinessState {
  pub fn new() -> Self {
    Self {
      last_auto_update: Timestamp::now(),
      manual_participant_liveness_refresh_requested: false,
    }
  }
}

// TODO: Refactor this. Maybe the repeating groups of "topic", "reader",
// "writer", "timer" below could be abstracted to a common struct:

pub(super) type DataReaderPlCdr<D> = DataReader<D, PlCdrDeserializerAdapter<D>>;
pub(super) type DataWriterPlCdr<D> = DataWriter<D, PlCdrSerializerAdapter<D>>;

mod with_key {
  use serde::{de::DeserializeOwned, Serialize};
  use mio_extras::timer::Timer;

  use super::{DataReaderPlCdr, DataWriterPlCdr};
  use crate::{
    polling::TimerPolicy, serialization::pl_cdr_adapters::*, Key, Keyed, Topic, TopicKind,
  };

  pub const TOPIC_KIND: TopicKind = TopicKind::WithKey;

  pub(super) struct DiscoveryTopicPlCdr<D>
  where
    D: Keyed + PlCdrSerialize + PlCdrDeserialize,
    <D as Keyed>::K: Key + PlCdrSerialize + PlCdrDeserialize,
  {
    #[allow(dead_code)] // The topic may not be accessed after initialization
    pub topic: Topic,
    pub reader: DataReaderPlCdr<D>,
    pub writer: DataWriterPlCdr<D>,
    pub timer: Timer<TimerPolicy>,
  }

  pub(super) struct DiscoveryTopicCDR<D>
  where
    D: Keyed + Serialize + DeserializeOwned,
    <D as Keyed>::K: Key + Serialize + DeserializeOwned,
  {
    #[allow(dead_code)] // The topic may not be accessed after initialization
    pub topic: Topic,
    pub reader: crate::with_key::DataReaderCdr<D>,
    pub writer: crate::with_key::DataWriterCdr<D>,
    pub timer: Timer<TimerPolicy>,
  }
}

#[cfg(feature = "security")] // only used with security feature for now, this is to avoid warning
mod no_key {
  use serde::{de::DeserializeOwned, Serialize};
  use mio_extras::timer::Timer;

  use crate::{polling::TimerPolicy, Topic, TopicKind};

  pub const TOPIC_KIND: TopicKind = TopicKind::NoKey;

  pub(super) struct DiscoveryTopicCDR<D>
  where
    D: Serialize + DeserializeOwned,
  {
    #[allow(dead_code)] // The topic may not be accessed after initialization
    pub topic: Topic,
    pub reader: crate::no_key::DataReader<D, crate::CDRDeserializerAdapter<D>>,
    pub writer: crate::no_key::DataWriter<D, crate::CDRSerializerAdapter<D>>,
    #[allow(dead_code)] // Timers currently not used for no_key discovery topics
    pub timer: Timer<TimerPolicy>,
  }
}

// Enum indicating if secure discovery allows normal discovery to process
// something
#[derive(PartialEq)]
pub(crate) enum NormalDiscoveryPermission {
  Allow,
  #[cfg(feature = "security")] // Deny variant is never constructed if security feature is not on
  Deny,
}

/*
pub(crate) struct Discovery {
  poll: Poll,
  domain_participant: DomainParticipantWeak,
  discovery_db: Arc<RwLock<DiscoveryDB>>,

  // Discovery started sender confirms to application thread that we are running
  discovery_started_sender: std::sync::mpsc::Sender<CreateResult<()>>,
  // notification sender goes to dp_event_loop thread
  discovery_updated_sender: mio_channel::SyncSender<DiscoveryNotificationType>,
  // Discovery gets commands from dp_event_loop from this channel
  discovery_command_receiver: mio_channel::Receiver<DiscoveryCommand>,
  spdp_liveness_receiver: mio_channel::Receiver<GuidPrefix>,

  liveliness_state: LivelinessState,

  participant_status_sender: StatusChannelSender<DomainParticipantStatusEvent>,

  // DDS Subscriber and Publisher for Discovery
  // ...but these are not actually used after initialization
  // discovery_subscriber: Subscriber,
  // discovery_publisher: Publisher,

  // Handling of "DCPSParticipant" topic. This is the mother of all topics
  // where participants announce their presence and built-in readers and writers.
  // and
  // timer to periodically announce our presence
  dcps_participant: with_key::DiscoveryTopicPlCdr<SpdpDiscoveredParticipantData>,
  participant_cleanup_timer: Timer<()>, // garbage collection timer for dead remote participants

  // Topic "DCPSSubscription" - announcing and detecting Readers
  dcps_subscription: with_key::DiscoveryTopicPlCdr<DiscoveredReaderData>,

  // Topic "DCPSPublication" - announcing and detecting Writers
  dcps_publication: with_key::DiscoveryTopicPlCdr<DiscoveredWriterData>,

  // Topic "DCPSTopic" - announcing and detecting topics
  dcps_topic: with_key::DiscoveryTopicPlCdr<DiscoveredTopicData>,
  topic_cleanup_timer: Timer<()>,

  // DCPSParticipantMessage - used by participants to communicate liveness
  dcps_participant_message: with_key::DiscoveryTopicCDR<ParticipantMessageData>,

  // If security is enabled, this field contains a SecureDiscovery struct, an appendix
  // which is used for Secure functionality
  security_opt: Option<SecureDiscovery>,

  // Following topics from DDS Security spec v1.1

  // DCPSParticipantSecure - 7.4.1.6 New DCPSParticipantSecure Builtin Topic
  #[cfg(feature = "security")]
  dcps_participant_secure: with_key::DiscoveryTopicPlCdr<ParticipantBuiltinTopicDataSecure>,

  // DCPSPublicationsSecure - 7.4.1.7 New DCPSPublicationsSecure Builtin Topic
  #[cfg(feature = "security")]
  dcps_publications_secure: with_key::DiscoveryTopicPlCdr<PublicationBuiltinTopicDataSecure>,

  // DCPSSubscriptionsSecure - 7.4.1.8 New DCPSSubscriptionsSecure Builtin Topic
  #[cfg(feature = "security")]
  dcps_subscriptions_secure: with_key::DiscoveryTopicPlCdr<SubscriptionBuiltinTopicDataSecure>,

  // DCPSParticipantMessageSecure - used by participants to communicate secure liveness
  // 7.4.2 New DCPSParticipantMessageSecure builtin Topic
  #[cfg(feature = "security")]
  dcps_participant_message_secure: with_key::DiscoveryTopicCDR<ParticipantMessageData>, /* CDR, not PL_CDR */

  // DCPSParticipantStatelessMessageSecure
  // 7.4.3 New DCPSParticipantStatelessMessage builtin Topic
  #[cfg(feature = "security")]
  dcps_participant_stateless_message: no_key::DiscoveryTopicCDR<ParticipantStatelessMessage>,

  // DCPSParticipantVolatileMessageSecure
  // 7.4.4 New DCPSParticipantVolatileMessageSecure builtin Topic
  #[cfg(feature = "security")]
  dcps_participant_volatile_message_secure:
    no_key::DiscoveryTopicCDR<ParticipantVolatileMessageSecure>, // CDR?

  #[cfg(feature = "security")]
  cached_secure_discovery_messages_resend_timer: Timer<()>,
}

impl Discovery {

  pub(crate) const PARTICIPANT_MESSAGE_QOS: QosPolicies = QosPolicies {
    durability: Some(Durability::TransientLocal),
    presentation: None,
    deadline: None,
    latency_budget: None,
    ownership: None,
    liveliness: None,
    time_based_filter: None,
    reliability: Some(Reliability::Reliable {
      max_blocking_time: Duration::ZERO,
    }),
    destination_order: None,
    history: Some(History::KeepLast { depth: 1 }),
    resource_limits: None,
    lifespan: None,
    #[cfg(feature = "security")]
    property: None,
  };

  #[allow(clippy::too_many_arguments)]
  pub fn new(
    domain_participant: DomainParticipantWeak,
    discovery_db: Arc<RwLock<DiscoveryDB>>,
    discovery_started_sender: std::sync::mpsc::Sender<CreateResult<()>>,
    discovery_updated_sender: mio_channel::SyncSender<DiscoveryNotificationType>,
    discovery_command_receiver: mio_channel::Receiver<DiscoveryCommand>,
    spdp_liveness_receiver: mio_channel::Receiver<GuidPrefix>,
    participant_status_sender: StatusChannelSender<DomainParticipantStatusEvent>,
    security_plugins_opt: Option<SecurityPluginsHandle>,
  ) -> CreateResult<Self> {
    // helper macro to handle initialization failures.
    macro_rules! try_construct {
      ($constructor:expr, $msg:literal) => {
        match $constructor {
          Ok(r) => r,
          Err(e) => {
            error!("{} {:?}", $msg, e);
            discovery_started_sender
              .send(Err(CreateError::OutOfResources {
                reason: $msg.to_string(),
              }))
              .unwrap_or(()); // We are trying to quit. If send fails, just ignore it.
            return Err(CreateError::OutOfResources {
              reason: $msg.to_string(),
            });
          }
        }
      };
    }

    let poll = try_construct!(mio_06::Poll::new(), "Failed to allocate discovery poll.");
    let discovery_subscriber_qos = Self::subscriber_qos();
    let discovery_publisher_qos = Self::publisher_qos();

    // Create DDS Publisher and Subscriber for Discovery.
    // These are needed to create DataWriter and DataReader objects
    let discovery_subscriber = try_construct!(
      domain_participant.create_subscriber(&discovery_subscriber_qos),
      "Unable to create Discovery Subscriber."
    );
    let discovery_publisher = try_construct!(
      domain_participant.create_publisher(&discovery_publisher_qos),
      "Unable to create Discovery Publisher."
    );

    // TODO: timeout value is not used. Remove.
    macro_rules! construct_topic_and_poll {
      ( $repr:ident, $has_key:ident,
        $topic_name:expr, $topic_type_name:expr, $message_type:ty,
        $endpoint_qos_opt:expr,
        $stateless_RTPS:expr,
        $reader_entity_id:expr, $reader_token:expr,
        $writer_entity_id:expr,
        $timeout_and_timer_token_opt:expr, ) => {{
        let endpoint_qos_opt_bind = $endpoint_qos_opt;
        let topic_qos_ref = if let Some(qos) = endpoint_qos_opt_bind.as_ref() {
          qos
        } else {
          &discovery_subscriber_qos
        };

        let publisher_qos: QosPolicies = if let Some(qos) = endpoint_qos_opt_bind.as_ref() {
          qos.clone()
        } else {
          discovery_publisher_qos.clone()
        };

        let topic = domain_participant
          .create_topic(
            $topic_name.to_string(),
            $topic_type_name.to_string(),
            topic_qos_ref,
            $has_key::TOPIC_KIND,
          )
          .expect("Unable to create topic. ");
        paste! {
          let reader =
            discovery_subscriber
            . [< create_datareader_with_entity_id_ $has_key >]
              ::<$message_type, [<$repr DeserializerAdapter>] <$message_type>>(
              &topic,
              $reader_entity_id,
              $endpoint_qos_opt,
              $stateless_RTPS,
            ).expect("Unable to create DataReader. ");

          let writer =
              discovery_publisher.[< create_datawriter_with_entity_id_ $has_key >]
                ::<$message_type, [<$repr SerializerAdapter>] <$message_type>>(
                $writer_entity_id,
                &topic,
                Some(publisher_qos),
                $stateless_RTPS,
              ).expect("Unable to create DataWriter .");
        }
        poll
          .register(&reader, $reader_token, Ready::readable(), PollOpt::edge())
          .expect("Failed to register a discovery reader to poll.");

        let mut timer: Timer<TimerPolicy> = new_simple_timer();
        let timeout_and_timer_token_opt: Option<(StdDuration, mio_06::Token)> =
          $timeout_and_timer_token_opt;
        if let Some((_timeout_value, timer_token)) = timeout_and_timer_token_opt {
          timer.set_timeout(StdDuration::from_millis(100), TimerPolicy::Repeat);
          poll
            .register(&timer, timer_token, Ready::readable(), PollOpt::edge())
            .expect("Unable to register timer token. ");
        }
        paste! { $has_key ::[<DiscoveryTopic $repr>] { topic, reader, writer, timer } }
      }}; // macro
    }

    try_construct!(
      poll.register(
        &discovery_command_receiver,
        DISCOVERY_COMMAND_TOKEN,
        Ready::readable(),
        PollOpt::edge(),
      ),
      "Failed to register Discovery poll."
    );

    try_construct!(
      poll.register(
        &spdp_liveness_receiver,
        SPDP_LIVENESS_TOKEN,
        Ready::readable(),
        PollOpt::edge(),
      ),
      "Failed to register Discovery poll."
    );

    // Participant
    let dcps_participant = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_PARTICIPANT,
      builtin_topic_type_names::DCPS_PARTICIPANT,
      SpdpDiscoveredParticipantData,
      Some(Self::create_spdp_participant_qos()),
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SPDP_BUILTIN_PARTICIPANT_READER,
      DISCOVERY_PARTICIPANT_DATA_TOKEN,
      EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER,
      Some((
        Self::SPDP_PUBLISH_PERIOD,
        DISCOVERY_SEND_PARTICIPANT_INFO_TOKEN,
      )),
    );

    // create lease duration check timer
    let mut participant_cleanup_timer: Timer<()> = new_simple_timer();
    participant_cleanup_timer.set_timeout(Self::PARTICIPANT_CLEANUP_PERIOD, ());
    try_construct!(
      poll.register(
        &participant_cleanup_timer,
        DISCOVERY_PARTICIPANT_CLEANUP_TOKEN,
        Ready::readable(),
        PollOpt::edge(),
      ),
      "Unable to create participant cleanup timer."
    );

    // Subscriptions: What are the Readers on the network and what are they
    // subscribing to?
    let dcps_subscription = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_SUBSCRIPTION,
      builtin_topic_type_names::DCPS_SUBSCRIPTION,
      DiscoveredReaderData,
      None,  // QoS
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_READER,
      DISCOVERY_READER_DATA_TOKEN,
      EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER,
      None, // No timer
    );

    // Publication : Who are the Writers here and elsewhere
    let dcps_publication = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_PUBLICATION,
      builtin_topic_type_names::DCPS_PUBLICATION,
      DiscoveredWriterData,
      None,  // QoS,
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SEDP_BUILTIN_PUBLICATIONS_READER,
      DISCOVERY_WRITER_DATA_TOKEN,
      EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER,
      None, // No timer
    );

    // Topic topic (not a typo)
    let dcps_topic = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_TOPIC,
      builtin_topic_type_names::DCPS_TOPIC,
      DiscoveredTopicData,
      None,  // QoS,
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SEDP_BUILTIN_TOPIC_READER,
      DISCOVERY_TOPIC_DATA_TOKEN,
      EntityId::SEDP_BUILTIN_TOPIC_WRITER,
      None, // No timer
    );

    // create lease duration check timer
    let mut topic_cleanup_timer: Timer<()> = new_simple_timer();
    topic_cleanup_timer.set_timeout(Self::TOPIC_CLEANUP_PERIOD, ());
    try_construct!(
      poll.register(
        &topic_cleanup_timer,
        DISCOVERY_TOPIC_CLEANUP_TOKEN,
        Ready::readable(),
        PollOpt::edge(),
      ),
      "Unable to register topic cleanup timer."
    );

    // Participant Message Data 8.4.13
    let dcps_participant_message = construct_topic_and_poll!(
      CDR,
      with_key,
      builtin_topic_names::DCPS_PARTICIPANT_MESSAGE,
      builtin_topic_type_names::DCPS_PARTICIPANT_MESSAGE,
      ParticipantMessageData,
      Some(Self::PARTICIPANT_MESSAGE_QOS),
      false, // Regular stateful RTPS Reader & Writer
      EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_READER,
      DISCOVERY_PARTICIPANT_MESSAGE_TOKEN,
      EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER,
      Some((
        Self::CHECK_PARTICIPANT_MESSAGES,
        DISCOVERY_PARTICIPANT_MESSAGE_TIMER_TOKEN,
      )),
    );

    // DDS Security

    // Participant
    #[cfg(feature = "security")]
    let dcps_participant_secure = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_PARTICIPANT_SECURE,
      builtin_topic_type_names::DCPS_PARTICIPANT_SECURE,
      ParticipantBuiltinTopicDataSecure,
      None,  // QoS
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SPDP_RELIABLE_BUILTIN_PARTICIPANT_SECURE_READER,
      SECURE_DISCOVERY_PARTICIPANT_DATA_TOKEN,
      EntityId::SPDP_RELIABLE_BUILTIN_PARTICIPANT_SECURE_WRITER,
      None, // No timer. Periodic sending is done simultaneously with the non-secure topic
    );

    // Subscriptions: What are the Readers on the network and what are they
    // subscribing to?
    #[cfg(feature = "security")]
    let dcps_subscriptions_secure = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_SUBSCRIPTIONS_SECURE,
      builtin_topic_type_names::DCPS_SUBSCRIPTIONS_SECURE,
      SubscriptionBuiltinTopicDataSecure,
      None,  // QoS
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_SECURE_READER,
      SECURE_DISCOVERY_READER_DATA_TOKEN,
      EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_SECURE_WRITER,
      None, // No timer
    );

    // Publication : Who are the Writers here and elsewhere
    #[cfg(feature = "security")]
    let dcps_publications_secure = construct_topic_and_poll!(
      PlCdr,
      with_key,
      builtin_topic_names::DCPS_PUBLICATIONS_SECURE,
      builtin_topic_type_names::DCPS_PUBLICATIONS_SECURE,
      PublicationBuiltinTopicDataSecure,
      None,  // QoS
      false, // Regular stateful RTPS Reader & Writer
      EntityId::SEDP_BUILTIN_PUBLICATIONS_SECURE_READER,
      SECURE_DISCOVERY_WRITER_DATA_TOKEN,
      EntityId::SEDP_BUILTIN_PUBLICATIONS_SECURE_WRITER,
      None, // No timer
    );

    // p2p Participant message secure
    #[cfg(feature = "security")]
    let dcps_participant_message_secure = construct_topic_and_poll!(
      CDR,
      with_key,
      builtin_topic_names::DCPS_PARTICIPANT_MESSAGE_SECURE,
      builtin_topic_type_names::DCPS_PARTICIPANT_MESSAGE_SECURE,
      ParticipantMessageData, // actually reuse the non-secure data type
      None,                   // QoS
      false,                  // Regular stateful RTPS Reader & Writer
      EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_SECURE_READER,
      P2P_SECURE_DISCOVERY_PARTICIPANT_MESSAGE_TOKEN,
      EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_SECURE_WRITER,
      None, // No timer. Periodic sending is done simultaneously with the non-secure topic
    );
    // p2p Participant stateless message, used for authentication and Diffie-Hellman
    // key exchange
    #[cfg(feature = "security")]
    let dcps_participant_stateless_message = construct_topic_and_poll!(
      CDR,
      no_key,
      builtin_topic_names::DCPS_PARTICIPANT_STATELESS_MESSAGE,
      builtin_topic_type_names::DCPS_PARTICIPANT_STATELESS_MESSAGE,
      ParticipantStatelessMessage,
      Some(Self::create_participant_stateless_message_qos()),
      true, // Important: STATELESS RTPS Reader & Writer (see Security spec. section 7.4.3)
      EntityId::P2P_BUILTIN_PARTICIPANT_STATELESS_READER,
      P2P_PARTICIPANT_STATELESS_MESSAGE_TOKEN,
      EntityId::P2P_BUILTIN_PARTICIPANT_STATELESS_WRITER,
      None, // No timer
    );

    // p2p Participant volatile message secure, used for key exchange
    // Used for distributing symmetric (AES) crypto keys
    #[cfg(feature = "security")]
    let dcps_participant_volatile_message_secure = construct_topic_and_poll!(
      CDR,
      no_key,
      builtin_topic_names::DCPS_PARTICIPANT_VOLATILE_MESSAGE_SECURE,
      builtin_topic_type_names::DCPS_PARTICIPANT_VOLATILE_MESSAGE_SECURE,
      ParticipantVolatileMessageSecure,
      Some(Self::create_participant_volatile_message_secure_qos()),
      false, // Regular stateful RTPS Reader & Writer
      EntityId::P2P_BUILTIN_PARTICIPANT_VOLATILE_SECURE_READER,
      P2P_BUILTIN_PARTICIPANT_VOLATILE_SECURE_TOKEN,
      EntityId::P2P_BUILTIN_PARTICIPANT_VOLATILE_SECURE_WRITER,
      None, // No timer.
    );

    // Create a timer to periodically check whether to resend any cached security
    // (authentication, key exchange) messages
    #[cfg(feature = "security")]
    let secure_message_resend_timer = {
      let mut secure_message_resend_timer: Timer<()> = new_simple_timer();
      secure_message_resend_timer
        .set_timeout(Self::CACHED_SECURE_DISCOVERY_MESSAGE_RESEND_PERIOD, ());
      try_construct!(
        poll.register(
          &secure_message_resend_timer,
          CACHED_SECURE_DISCOVERY_MESSAGE_RESEND_TIMER_TOKEN,
          Ready::readable(),
          PollOpt::edge(),
        ),
        "Unable to create secure message resend timer."
      );
      secure_message_resend_timer
    };

    #[cfg(not(feature = "security"))]
    let security_opt = security_plugins_opt.and(None); // = None, but avoid warning.

    #[cfg(feature = "security")]
    let security_opt = if let Some(plugins_handle) = security_plugins_opt {
      // Plugins is Some so security is enabled. Initialize SecureDiscovery
      let security = try_construct!(
        SecureDiscovery::new(&domain_participant, &discovery_db, plugins_handle),
        "Could not initialize Secure Discovery."
      );
      Some(security)
    } else {
      None // no security configured
    };

    Ok(Self {
      poll,
      domain_participant,
      discovery_db,
      discovery_started_sender,
      discovery_updated_sender,
      discovery_command_receiver,
      spdp_liveness_receiver,
      participant_status_sender,

      liveliness_state: LivelinessState::new(),

      // discovery_subscriber,
      // discovery_publisher,
      dcps_participant,
      participant_cleanup_timer, // SPDP
      dcps_subscription,
      dcps_publication, // SEDP
      dcps_topic,
      topic_cleanup_timer,      // SEDP
      dcps_participant_message, // liveliness messages

      security_opt,
      #[cfg(feature = "security")]
      dcps_participant_secure,
      #[cfg(feature = "security")]
      dcps_publications_secure,
      #[cfg(feature = "security")]
      dcps_subscriptions_secure,
      #[cfg(feature = "security")]
      dcps_participant_message_secure,
      #[cfg(feature = "security")]
      dcps_participant_stateless_message,
      #[cfg(feature = "security")]
      dcps_participant_volatile_message_secure,
      #[cfg(feature = "security")]
      cached_secure_discovery_messages_resend_timer: secure_message_resend_timer,
    })
  }

  pub fn discovery_event_loop(&mut self) {
    self.initialize_participant();

    // send out info about non-built-in Writers and Readers that we have.
    self.sedp_publish_writers();
    self.sedp_publish_readers();

    match self.discovery_started_sender.send(Ok(())) {
      Ok(_) => (),
      _ => return, // Participant has probably crashed at this point
    };

    loop {
      let mut events = Events::with_capacity(32); // Should this be outside of the loop?
      match self
        .poll
        .poll(&mut events, Some(std::time::Duration::from_millis(5000)))
      {
        Ok(_) => (),
        Err(e) => {
          error!("Failed in waiting of poll in discovery. {e:?}");
          return;
        }
      }
      if events.is_empty() {
        debug!("Discovery event loop idling.");
      }

      for event in events.into_iter() {
        match event.token() {
          DISCOVERY_COMMAND_TOKEN => {
            while let Ok(command) = self.discovery_command_receiver.try_recv() {
              match command {
                DiscoveryCommand::StopDiscovery => {
                  info!("Stopping Discovery");
                  self.on_participant_shutting_down();
                  info!("Stopped Discovery");
                  return; // terminate event loop
                }
                DiscoveryCommand::AddLocalWriter { guid } => {
                  self.sedp_publish_single_writer(guid);
                }
                DiscoveryCommand::AddLocalReader { guid } => {
                  self.sedp_publish_single_reader(guid);
                }
                DiscoveryCommand::AddTopic { topic_name } => {
                  self.sedp_publish_topic(&topic_name);
                }
                DiscoveryCommand::RemoveLocalWriter { guid } => {
                  if guid == self.dcps_publication.writer.guid() {
                    continue;
                  }
                  self.send_endpoint_dispose_message(guid);
                  discovery_db_write(&self.discovery_db).remove_local_topic_writer(guid);
                }
                DiscoveryCommand::RemoveLocalReader { guid } => {
                  if guid == self.dcps_subscription.writer.guid() {
                    continue;
                  }
                  self.send_endpoint_dispose_message(guid);
                  discovery_db_write(&self.discovery_db).remove_local_topic_reader(guid);
                }
                DiscoveryCommand::ManualAssertLiveliness => {
                  self
                    .liveliness_state
                    .manual_participant_liveness_refresh_requested = true;
                }
                DiscoveryCommand::AssertTopicLiveliness {
                  writer_guid,
                  manual_assertion,
                } => {
                  self.send_discovery_notification(
                    DiscoveryNotificationType::AssertTopicLiveliness {
                      writer_guid,
                      manual_assertion,
                    },
                  );
                }
                #[cfg(feature = "security")]
                DiscoveryCommand::StartKeyExchangeWithRemoteParticipant {
                  participant_guid_prefix,
                } => {
                  if let Some(security) = self.security_opt.as_mut() {
                    security.start_key_exchange_with_remote_participant(
                      participant_guid_prefix,
                      &self.dcps_participant_volatile_message_secure.writer,
                      &self.discovery_db,
                    );
                  }
                }
                #[cfg(feature = "security")]
                DiscoveryCommand::StartKeyExchangeWithRemoteEndpoint {
                  local_endpoint_guid,
                  remote_endpoint_guid,
                } => {
                  if let Some(security) = self.security_opt.as_mut() {
                    security.start_key_exchange_with_remote_endpoint(
                      local_endpoint_guid,
                      remote_endpoint_guid,
                      &self.dcps_participant_volatile_message_secure.writer,
                      &self.discovery_db,
                    );
                  }
                }
              };
            }
          }

          DISCOVERY_PARTICIPANT_DATA_TOKEN => {
            debug!("triggered participant reader");
            self.spdp_receive();
          }

          DISCOVERY_PARTICIPANT_CLEANUP_TOKEN => {
            self.participant_cleanup();
            // setting next cleanup timeout
            self
              .participant_cleanup_timer
              .set_timeout(Self::PARTICIPANT_CLEANUP_PERIOD, ());
          }

          DISCOVERY_SEND_PARTICIPANT_INFO_TOKEN => {
            if let Some(dp) = self.domain_participant.clone().upgrade() {
              self.spdp_publish(&dp);
            } else {
              error!("DomainParticipant doesn't exist anymore, exiting Discovery.");
              return;
            };
            // reschedule timer
            while let Some(policy) = self.dcps_participant.timer.poll() {
              match policy {
                TimerPolicy::Repeat => {
                  self
                    .dcps_participant
                    .timer
                    .set_timeout(Self::SPDP_PUBLISH_PERIOD, TimerPolicy::Repeat);
                }
                TimerPolicy::OneShot => {
                  // Do not set again, since it was one-shot.
                }
              }
            }
          }
          DISCOVERY_READER_DATA_TOKEN => {
            self.sedp_receive_subscription(None);
          }
          DISCOVERY_WRITER_DATA_TOKEN => {
            self.sedp_receive_publication(None);
          }
          DISCOVERY_TOPIC_DATA_TOKEN => {
            self.sedp_receive_topic_data(None);
          }
          DISCOVERY_TOPIC_CLEANUP_TOKEN => {
            self.topic_cleanup();

            self
              .topic_cleanup_timer
              .set_timeout(Self::TOPIC_CLEANUP_PERIOD, ());
          }
          DISCOVERY_PARTICIPANT_MESSAGE_TOKEN | P2P_SECURE_DISCOVERY_PARTICIPANT_MESSAGE_TOKEN => {
            self.receive_participant_message();
          }
          DISCOVERY_PARTICIPANT_MESSAGE_TIMER_TOKEN => {
            self.publish_participant_message();
            self
              .dcps_participant_message
              .timer
              .set_timeout(Self::CHECK_PARTICIPANT_MESSAGES, TimerPolicy::Repeat);
          }
          SPDP_LIVENESS_TOKEN => {
            while let Ok(guid_prefix) = self.spdp_liveness_receiver.try_recv() {
              discovery_db_write(&self.discovery_db).participant_is_alive(guid_prefix);
            }
          }
          P2P_PARTICIPANT_STATELESS_MESSAGE_TOKEN => {
            #[cfg(feature = "security")]
            self.receive_participant_stateless_message();
          }
          CACHED_SECURE_DISCOVERY_MESSAGE_RESEND_TIMER_TOKEN => {
            #[cfg(feature = "security")]
            self.on_secure_discovery_message_resend_triggered();
          }
          P2P_BUILTIN_PARTICIPANT_VOLATILE_SECURE_TOKEN => {
            #[cfg(feature = "security")]
            self.receive_participant_volatile_message();
          }
          SECURE_DISCOVERY_PARTICIPANT_DATA_TOKEN => {
            #[cfg(feature = "security")]
            self.secure_spdp_receive();
          }
          SECURE_DISCOVERY_READER_DATA_TOKEN => {
            #[cfg(feature = "security")]
            self.secure_sedp_receive_subscription(None);
          }
          SECURE_DISCOVERY_WRITER_DATA_TOKEN => {
            #[cfg(feature = "security")]
            self.secure_sedp_receive_publication(None);
          }

          other_token => {
            error!("discovery event loop got token: {:?}", other_token);
          }
        } // match
      } // for
    } // loop
  } // fn

  // Initialize our own participant data into the Discovery DB.
  // That causes ReaderProxies and WriterProxies to be constructed and
  // and we also get our own local readers and writers connected, both
  // built-in and user-defined.
  // If we did not do this, the Readers and Writers in this participant could not
  // find each other.
  fn initialize_participant(&self) {
    let dp = if let Some(dp) = self.domain_participant.clone().upgrade() {
      dp
    } else {
      error!("Cannot get actual DomainParticipant in initialize_participant! Giving up.");
      return;
    };

    let participant_data = SpdpDiscoveredParticipantData::from_local_participant(
      &dp,
      &self.security_opt,
      Duration::INFINITE,
    );

    // Initialize our own participant data into the Discovery DB, so we can talk to
    // ourself.
    discovery_db_write(&self.discovery_db).update_participant(&participant_data);

    // This will read the participant from Discovery DB and construct
    // ReaderProxy and WriterProxy objects for built-in Readers and Writers
    self.send_discovery_notification(DiscoveryNotificationType::ParticipantUpdated {
      guid_prefix: dp.guid().prefix,
    });
  }

  pub fn spdp_receive(&mut self) {
    loop {
      let s = self.dcps_participant.reader.take_next_sample();
      debug!("spdp_receive read {:?}", &s);
      match s {
        Ok(Some(ds)) => {
          #[cfg(not(feature = "security"))]
          let permission = NormalDiscoveryPermission::Allow;

          #[cfg(feature = "security")]
          let permission = if let Some(security) = self.security_opt.as_mut() {
            // Security is enabled. Do a secure read, potentially starting the
            // authentication protocol. The return value tells if normal Discovery is
            // allowed to process the message.
            security.participant_read(
              &ds,
              &self.discovery_db,
              &self.discovery_updated_sender,
              &self.dcps_participant_stateless_message.writer,
            )
          } else {
            // No security configured, always allowed
            NormalDiscoveryPermission::Allow
          };

          if permission == NormalDiscoveryPermission::Allow {
            match ds.value {
              Sample::Value(participant_data) => {
                debug!("spdp_receive discovered {:?}", &participant_data);
                self.process_discovered_participant_data(&participant_data);
              }
              // Sample::Dispose means that DomainParticipant was disposed
              Sample::Dispose(participant_guid) => {
                self.process_participant_dispose(participant_guid.0.prefix);
              }
            }
          }
        }
        Ok(None) => {
          trace!("spdp_receive: no more data");
          return;
        } // no more data
        Err(e) => {
          error!(" !!! spdp_receive: {e:?}");
          return;
        }
      }
    } // loop
  }

  fn process_discovered_participant_data(
    &mut self,
    participant_data: &SpdpDiscoveredParticipantData,
  ) {
    let was_new = discovery_db_write(&self.discovery_db).update_participant(participant_data);
    let guid_prefix = participant_data.participant_guid.prefix;
    self.send_discovery_notification(DiscoveryNotificationType::ParticipantUpdated { guid_prefix });
    if was_new {
      // Inform DDS Applications
      self.send_participant_status(DomainParticipantStatusEvent::ParticipantDiscovered {
        dpd: participant_data.into(),
      });

      // Send a quick response to make discovery faster.
      //
      // RTPS spec v2.5 Section "8.5.3.1 General Approach" [to SPDP] says
      // "Implementations can minimize any start-up delays by sending an additional
      // SPDPdiscoveredParticipantData in response to receiving this data-object from
      // a previously unknown Participant, but this behavior is optional."
      //
      // But not to reply to self, because we know that we exist.
      // TODO: Maybe add some rate-limiting to this to avoid packet storms.
      if guid_prefix != self.domain_participant.guid().prefix {
        self
          .dcps_participant
          .timer
          .set_timeout(StdDuration::from_millis(10), TimerPolicy::OneShot);
      }

      // This may be a rediscovery of a previously seen participant that
      // was temporarily lost due to network outage. Check if we already know
      // what it has (readers, writers, topics).
      debug!("Participant rediscovery start");
      self.sedp_receive_topic_data(Some(guid_prefix));
      self.sedp_receive_subscription(Some(guid_prefix));
      self.sedp_receive_publication(Some(guid_prefix));
      debug!("Participant rediscovery finished");
    }
  }

  fn process_participant_dispose(&mut self, participant_guidp: GuidPrefix) {
    discovery_db_write(&self.discovery_db).remove_participant(participant_guidp, true); // true = actively removed
    self.send_discovery_notification(DiscoveryNotificationType::ParticipantLost {
      guid_prefix: participant_guidp,
    });
    self.send_participant_status(DomainParticipantStatusEvent::ParticipantLost {
      id: participant_guidp,
      reason: LostReason::Disposed,
    });
  }

  fn send_endpoint_dispose_message(&self, endpoint_guid: GUID) {
    let is_writer = endpoint_guid.entity_id.entity_kind.is_writer();
    if is_writer {
      self
        .dcps_publication
        .writer
        .dispose(&Endpoint_GUID(endpoint_guid), None)
        .unwrap_or_else(|e| error!("Disposing local Writer: {e:?}"));
      #[cfg(feature = "security")]
      self
        .dcps_publications_secure
        .writer
        .dispose(&Endpoint_GUID(endpoint_guid), None)
        .unwrap_or_else(|e| error!("Disposing local Writer: {e:?}"));
    } else {
      // is reader
      self
        .dcps_subscription
        .writer
        .dispose(&Endpoint_GUID(endpoint_guid), None)
        .unwrap_or_else(|e| error!("Disposing local Reader: {e:?}"));
      #[cfg(feature = "security")]
      self
        .dcps_subscriptions_secure
        .writer
        .dispose(&Endpoint_GUID(endpoint_guid), None)
        .unwrap_or_else(|e| error!("Disposing local Reader: {e:?}"));
    }
  }

  fn on_participant_shutting_down(&mut self) {
    let db = discovery_db_read(&self.discovery_db);

    for reader in db.get_all_local_topic_readers() {
      self.send_endpoint_dispose_message(reader.reader_proxy.remote_reader_guid);
    }

    for writer in db.get_all_local_topic_writers() {
      self.send_endpoint_dispose_message(writer.writer_proxy.remote_writer_guid);
    }

    self
      .dcps_participant
      .writer
      .dispose(&Participant_GUID(self.domain_participant.guid()), None)
      .unwrap_or(());
    #[cfg(feature = "security")]
    self
      .dcps_participant_secure
      .writer
      .dispose(&Participant_GUID(self.domain_participant.guid()), None)
      .unwrap_or(());
  }

  // Check if there are messages about new Readers
  pub fn sedp_receive_subscription(&mut self, read_history: Option<GuidPrefix>) {
    let drds: Vec<Sample<DiscoveredReaderData, GUID>> =
      match self.dcps_subscription.reader.into_iterator() {
        Ok(ds) => ds
          .map(|d| d.map_dispose(|g| g.0)) // map_dispose removes Endpoint_GUID wrapper around GUID
          .filter(|d|
              // If a participant was specified, we must match its GUID prefix.
              match (read_history, d) {
                (None, _) => true, // Not asked to filter by participant
                (Some(participant_to_update), Sample::Value(drd)) =>
                  drd.reader_proxy.remote_reader_guid.prefix == participant_to_update,
                (Some(participant_to_update), Sample::Dispose(guid)) =>
                  guid.prefix == participant_to_update,
              })
          .collect(),
        Err(e) => {
          error!("sedp_receive_subscription: {e:?}");
          return;
        }
      };

    for d in drds {
      #[cfg(not(feature = "security"))]
      let permission = NormalDiscoveryPermission::Allow;

      #[cfg(feature = "security")]
      let permission = if let Some(security) = self.security_opt.as_mut() {
        // Security is enabled. Do a secure read
        security.check_nonsecure_subscription_read(&d, &self.discovery_db)
      } else {
        // No security configured, always allowed
        NormalDiscoveryPermission::Allow
      };

      if permission == NormalDiscoveryPermission::Allow {
        match d {
          Sample::Value(d) => {
            let drd = discovery_db_write(&self.discovery_db).update_subscription(&d);
            debug!(
              "sedp_receive_subscription - send_discovery_notification ReaderUpdated  {:?}",
              &drd
            );
            self.send_discovery_notification(DiscoveryNotificationType::ReaderUpdated {
              discovered_reader_data: drd,
            });
            if read_history.is_some() {
              info!(
                "Rediscovered reader {:?} topic={:?}",
                d.reader_proxy.remote_reader_guid,
                d.subscription_topic_data.topic_name()
              );
            }
          }
          Sample::Dispose(reader_key) => {
            info!("Dispose Reader {:?}", reader_key);
            discovery_db_write(&self.discovery_db).remove_topic_reader(reader_key);
            self.send_discovery_notification(DiscoveryNotificationType::ReaderLost {
              reader_guid: reader_key,
            });
            self.send_participant_status(DomainParticipantStatusEvent::ReaderLost {
              guid: reader_key,
              reason: LostReason::Disposed,
            });
          }
        }
      }
    } // loop
  }

  pub fn sedp_receive_publication(&mut self, read_history: Option<GuidPrefix>) {
    let dwds: Vec<Sample<DiscoveredWriterData, GUID>> =
      match self.dcps_publication.reader.into_iterator() {
        // a lot of cloning here, but we must copy the data out of the
        // reader before we can use self again, as .read() returns references to within
        // a reader and thus self
        Ok(ds) => ds
          .map(|d| d.map_dispose(|g| g.0)) // map_dispose removes Endpoint_GUID wrapper around GUID
          // If a participant was specified, we must match its GUID prefix.
          .filter(|d| match (read_history, d) {
            (None, _) => true, // Not asked to filter by participant
            (Some(participant_to_update), Sample::Value(dwd)) => {
              dwd.writer_proxy.remote_writer_guid.prefix == participant_to_update
            }
            (Some(participant_to_update), Sample::Dispose(guid)) => {
              guid.prefix == participant_to_update
            }
          })
          .collect(),
        Err(e) => {
          error!("sedp_receive_publication: {e:?}");
          return;
        }
      };

    for d in dwds {
      #[cfg(not(feature = "security"))]
      let permission = NormalDiscoveryPermission::Allow;

      #[cfg(feature = "security")]
      let permission = if let Some(security) = self.security_opt.as_mut() {
        // Security is enabled. Do a secure read
        security.check_nonsecure_publication_read(&d, &self.discovery_db)
      } else {
        // No security configured, always allowed
        NormalDiscoveryPermission::Allow
      };

      if permission == NormalDiscoveryPermission::Allow {
        match d {
          Sample::Value(dwd) => {
            trace!("sedp_receive_publication discovered {:?}", &dwd);
            let discovered_writer_data =
              discovery_db_write(&self.discovery_db).update_publication(&dwd);
            self.send_discovery_notification(DiscoveryNotificationType::WriterUpdated {
              discovered_writer_data,
            });
            debug!("Discovered Writer {:?}", &dwd);
          }
          Sample::Dispose(writer_key) => {
            discovery_db_write(&self.discovery_db).remove_topic_writer(writer_key);
            self.send_discovery_notification(DiscoveryNotificationType::WriterLost {
              writer_guid: writer_key,
            });
            self.send_participant_status(DomainParticipantStatusEvent::WriterLost {
              guid: writer_key,
              reason: LostReason::Disposed,
            });

            debug!("Disposed Writer {:?}", writer_key);
          }
        }
      }
    } // loop
  }

  // TODO: Try to remember why the read_history parameter below was introduced
  // in the first place. Git history should help here.
  // Likely it is something to do with an unreliable network and
  // DomainParticipants timing out and then coming back. The read_history was
  // supposed to help in recovering from that.
  pub fn sedp_receive_topic_data(&mut self, _read_history: Option<GuidPrefix>) {
    let ts: Vec<Sample<(DiscoveredTopicData, GUID), GUID>> = match self
      .dcps_topic
      .reader
      .take(usize::MAX, ReadCondition::any())
    {
      Ok(ds) => ds
        .iter()
        .map(|d| {
          d.value
            .clone()
            .map_value(|o| (o, d.sample_info.writer_guid()))
            .map_dispose(|g| g.0)
        })
        .collect(),
      Err(e) => {
        error!("sedp_receive_topic_data: {e:?}");
        return;
      }
    };

    for t in ts {
      #[cfg(not(feature = "security"))]
      let permission = NormalDiscoveryPermission::Allow;

      #[cfg(feature = "security")]
      let permission = if let Some(security) = self.security_opt.as_mut() {
        // Security is enabled. Do a secure read
        security.check_topic_read(&t, &self.discovery_db)
      } else {
        // No security configured, always allowed
        NormalDiscoveryPermission::Allow
      };

      if permission == NormalDiscoveryPermission::Allow {
        match t {
          Sample::Value((topic_data, writer)) => {
            debug!("sedp_receive_topic_data discovered {:?}", &topic_data);
            discovery_db_write(&self.discovery_db).update_topic_data(
              &topic_data,
              writer,
              DiscoveredVia::Topic,
            );
            // Now check if we know any readers of writers to this topic. The topic QoS
            // could cause these to became viable matches against local
            // writers/readers. This is because at least RTI Connext sends QoS
            // policies on a Topic, and then (apparently) assumes that its
            // readers/writers inherit those policies unless specified otherwise.

            // Note that additional security checks are not needed here, since if a
            // reader/writer is in our DiscoveryDB, it has already passed the security
            // checks.
            let writers = discovery_db_read(&self.discovery_db)
              .writers_on_topic_and_participant(topic_data.topic_name(), writer.prefix);
            debug!("writers {:?}", &writers);
            for discovered_writer_data in writers {
              self.send_discovery_notification(DiscoveryNotificationType::WriterUpdated {
                discovered_writer_data,
              });
            }

            let readers = discovery_db_read(&self.discovery_db)
              .readers_on_topic_and_participant(topic_data.topic_name(), writer.prefix);
            for discovered_reader_data in readers {
              self.send_discovery_notification(DiscoveryNotificationType::ReaderUpdated {
                discovered_reader_data,
              });
            }
          }
          // Sample::Dispose means disposed
          Sample::Dispose(key) => {
            warn!("not implemented - Topic was disposed: {:?}", &key);
          }
        }
      }
    } // loop
  }

  // These messages are for updating participant liveliness
  // The protocol distinguishes between automatic (by DDS library)
  // and manual (by by application, via DDS API call) liveness
  pub fn receive_participant_message(&mut self) {
    // First read from nonsecure reader
    let mut samples = match self
      .dcps_participant_message
      .reader
      .take(usize::MAX, ReadCondition::any())
    {
      Ok(nonsecure_samples) => nonsecure_samples,
      Err(e) => {
        error!("receive_participant_message: {e:?}");
        return;
      }
    };

    // Then from secure reader if needed
    #[cfg(not(feature = "security"))]
    let mut secure_samples = vec![];
    #[cfg(feature = "security")]
    let mut secure_samples = match self
      .dcps_participant_message_secure
      .reader
      .take(usize::MAX, ReadCondition::any())
    {
      Ok(secure_samples) => secure_samples,
      Err(e) => {
        error!("Secure receive_participant_message: {e:?}");
        return;
      }
    };

    samples.append(&mut secure_samples);

    let msgs = samples
      .into_iter()
      .filter_map(|p| p.value().clone().value());

    let mut db = discovery_db_write(&self.discovery_db);
    for msg in msgs {
      db.update_lease_duration(&msg);
    }
  }

  fn spdp_publish(&self, local_dp: &DomainParticipant) {
    // setting 5 times the duration so lease doesn't break if update fails once or
    // twice
    let data = Spdppub(crate) DiscoveredParticipantData::from_local_participant(
      local_dp,
      &self.security_opt,
      5.0 * Duration::from(Self::SPDP_PUBLISH_PERIOD),
    );

    #[cfg(feature = "security")]
    if let Some(security) = self.security_opt.as_ref() {
      security.secure_spdp_publish(&self.dcps_participant_secure.writer, data.clone());
    }

    self
      .dcps_participant
      .writer
      .write(data, None)
      .unwrap_or_else(|e| {
        error!("Discovery: Publishing to DCPS participant topic failed: {e:?}");
      });
  }

  pub fn publish_participant_message(&mut self) {
    // Inspect if we need to send liveness messages
    // See 8.4.13.5 "Implementing Writer Liveliness Protocol .." in the RPTS spec

    // Dig out the smallest lease duration for writers with Automatic liveliness QoS
    let writer_livelinesses: Vec<Liveliness> = discovery_db_read(&self.discovery_db)
      .get_all_local_topic_writers()
      .filter_map(|p| p.publication_topic_data.liveliness)
      .collect();

    let min_automatic_lease_duration_opt = writer_livelinesses
      .iter()
      .filter_map(|liveliness| match liveliness {
        Liveliness::Automatic { lease_duration } => Some(*lease_duration),
        _other => None,
      })
      .min();

    let timenow = Timestamp::now();

    let mut messages_to_be_sent: Vec<ParticipantMessageData> = vec![];

    // Send Automatic liveness update if needed
    if let Some(min_auto_duration) = min_automatic_lease_duration_opt {
      let time_since_last_auto_update =
        timenow.duration_since(self.liveliness_state.last_auto_update);
      trace!(
        "time_since_last_auto_update: {:?}, min_auto_duration {:?}",
        time_since_last_auto_update,
        min_auto_duration
      );

      // We choose to send a new liveliness message if longer than half of the min
      // auto duration has elapsed since last message
      if time_since_last_auto_update > min_auto_duration / 2 {
        let msg = ParticipantMessageData {
          guid: self.domain_participant.guid_prefix(),
          kind: ParticipantMessageDataKind::AUTOMATIC_LIVELINESS_UPDATE,
          data: Vec::new(),
        };
        messages_to_be_sent.push(msg);
      }
    }

    // Send ManualByParticipant liveliness update if someone has requested us to do
    // so.
    // Note: According to the RTPS spec (8.7.2.2.3 LIVELINESS) the interval at which
    // we check if we need to send a manual liveness update should depend on the
    // lease durations of writers with ManualByParticipant liveness QoS.
    // Now we just check this at the same interval as with Automatic liveness.
    // So TODO if needed: comply with the spec.
    if self
      .liveliness_state
      .manual_participant_liveness_refresh_requested
    {
      let msg = ParticipantMessageData {
        guid: self.domain_participant.guid_prefix(),
        kind: ParticipantMessageDataKind::MANUAL_LIVELINESS_UPDATE,
        data: Vec::new(),
      };
      messages_to_be_sent.push(msg);
    }

    for msg in messages_to_be_sent {
      let msg_kind = msg.kind;

      #[cfg(not(feature = "security"))]
      let write_result = self.dcps_participant_message.writer.write(msg, None);

      #[cfg(feature = "security")]
      let write_result = if let Some(security) = self.security_opt.as_ref() {
        security.write_liveness_message(
          &self.dcps_participant_message_secure.writer,
          &self.dcps_participant_message.writer,
          msg,
        )
      } else {
        // No security enabled
        self.dcps_participant_message.writer.write(msg, None)
      };

      match write_result {
        Ok(_) => {
          match msg_kind {
            ParticipantMessageDataKind::AUTOMATIC_LIVELINESS_UPDATE => {
              self.liveliness_state.last_auto_update = timenow;
            }
            ParticipantMessageDataKind::MANUAL_LIVELINESS_UPDATE => {
              // We delivered what was requested
              self
                .liveliness_state
                .manual_participant_liveness_refresh_requested = false;
            }
            _ => (),
          }
        }
        Err(e) => {
          error!("Failed to writer ParticipantMessageData. {e:?}");
        }
      }
    }
  }

  #[cfg(feature = "security")]
  fn receive_participant_stateless_message(&mut self) {
    if let Some(security) = self.security_opt.as_mut() {
      // Security enabled. Get messages from the stateless data reader & feed to
      // Secure Discovery.
      match self
        .dcps_participant_stateless_message
        .reader
        .into_iterator()
      {
        Ok(dr_iter) => {
          for msg in dr_iter {
            security.participant_stateless_message_read(
              &msg,
              &self.discovery_db,
              &self.discovery_updated_sender,
              &self.dcps_participant_stateless_message.writer,
            );
          }
        }
        Err(e) => {
          error!("receive_participant_stateless_message: {e:?}");
        }
      };
    }
  }

  #[cfg(feature = "security")]
  fn receive_participant_volatile_message(&mut self) {
    if let Some(security) = self.security_opt.as_mut() {
      // Security enabled. Get messages from the volatile message reader & feed to
      // Secure Discovery.
      match self
        .dcps_participant_volatile_message_secure
        .reader
        .into_iterator()
      {
        Ok(dr_iter) => {
          for msg in dr_iter {
            security.volatile_message_secure_read(&msg);
          }
        }
        Err(e) => {
          error!("receive_participant_volatile_message: {e:?}");
        }
      };
    }
  }

  #[cfg(feature = "security")]
  pub fn secure_spdp_receive(&mut self) {
    let sample_iter = match self.dcps_participant_secure.reader.into_iterator() {
      Ok(iter) => iter,
      Err(e) => {
        error!("secure_spdp_receive: {e:?}");
        return;
      }
    };

    for sample in sample_iter {
      let permission = if let Some(security) = self.security_opt.as_mut() {
        security.secure_participant_read(
          &sample,
          &self.discovery_db,
          &self.discovery_updated_sender,
        )
      } else {
        debug!("In secure_spdp_receive even though security not enabled?");
        return;
      };

      if permission == NormalDiscoveryPermission::Allow {
        match sample {
          Sample::Value(sec_data) => {
            let participant_data = sec_data.participant_data;
            self.process_discovered_participant_data(&participant_data);
          }
          // Sample::Dispose means that DomainParticipant was disposed
          Sample::Dispose(participant_guid) => {
            self.process_participant_dispose(participant_guid.0.prefix);
          }
        }
      }
    }
  }

  #[cfg(feature = "security")]
  pub fn secure_sedp_receive_subscription(&mut self, read_history: Option<GuidPrefix>) {
    let sec_subs: Vec<Sample<SubscriptionBuiltinTopicDataSecure, GUID>> =
      match self.dcps_subscriptions_secure.reader.into_iterator() {
        Ok(ds) => ds
          .map(|d| d.map_dispose(|g| g.0)) // map_dispose removes Endpoint_GUID wrapper around GUID
          .filter(|d|
              // If a participant was specified, we must match its GUID prefix.
              match (read_history, d) {
                (None, _) => true, // Not asked to filter by participant
                (Some(participant_to_update), Sample::Value(sec_sub)) =>
                sec_sub.discovered_reader_data.reader_proxy.remote_reader_guid.prefix == participant_to_update,
                (Some(participant_to_update), Sample::Dispose(guid)) =>
                  guid.prefix == participant_to_update,
              })
          .collect(),
        Err(e) => {
          error!("secure_sedp_receive_subscription: {e:?}");
          return;
        }
      };

    for sec_sub_sample in sec_subs {
      let permission = if let Some(security) = self.security_opt.as_mut() {
        security.check_secure_subscription_read(&sec_sub_sample, &self.discovery_db)
      } else {
        debug!("In secure_sedp_receive_subscription even though security not enabled?");
        return;
      };

      if permission == NormalDiscoveryPermission::Allow {
        match sec_sub_sample {
          Sample::Value(sec_sub) => {
            // Currently we use only the DiscoveredReaderData field, no DataTag
            let drd_from_topic = sec_sub.discovered_reader_data;
            let drd = discovery_db_write(&self.discovery_db).update_subscription(&drd_from_topic);
            self.send_discovery_notification(DiscoveryNotificationType::ReaderUpdated {
              discovered_reader_data: drd,
            });
          }
          Sample::Dispose(reader_guid) => {
            info!("Secure Dispose Reader {:?}", reader_guid);
            discovery_db_write(&self.discovery_db).remove_topic_reader(reader_guid);
            self.send_discovery_notification(DiscoveryNotificationType::ReaderLost { reader_guid });
            self.send_participant_status(DomainParticipantStatusEvent::ReaderLost {
              guid: reader_guid,
              reason: LostReason::Disposed,
            });
          }
        }
      }
    }
  }

  #[cfg(feature = "security")]
  pub fn secure_sedp_receive_publication(&mut self, read_history: Option<GuidPrefix>) {
    let sec_pubs: Vec<Sample<PublicationBuiltinTopicDataSecure, GUID>> =
      match self.dcps_publications_secure.reader.into_iterator() {
        Ok(ds) => ds
          .map(|d| d.map_dispose(|g| g.0)) // map_dispose removes Endpoint_GUID wrapper around GUID
          // If a participant was specified, we must match its GUID prefix.
          .filter(|d| match (read_history, d) {
            (None, _) => true, // Not asked to filter by participant
            (Some(participant_to_update), Sample::Value(sec_pub)) => {
              sec_pub
                .discovered_writer_data
                .writer_proxy
                .remote_writer_guid
                .prefix
                == participant_to_update
            }
            (Some(participant_to_update), Sample::Dispose(guid)) => {
              guid.prefix == participant_to_update
            }
          })
          .collect(),
        Err(e) => {
          error!("secure_sedp_receive_publication: {e:?}");
          return;
        }
      };

    for sec_pub_sample in sec_pubs {
      let permission = if let Some(security) = self.security_opt.as_mut() {
        security.check_secure_publication_read(&sec_pub_sample, &self.discovery_db)
      } else {
        debug!("In secure_sedp_receive_publication even though security not enabled?");
        return;
      };

      if permission == NormalDiscoveryPermission::Allow {
        match sec_pub_sample {
          Sample::Value(se_pub) => {
            // Currently we use only the DiscoveredWriterData field, no DataTag
            let dwd_from_topic = se_pub.discovered_writer_data;
            let dwd = discovery_db_write(&self.discovery_db).update_publication(&dwd_from_topic);
            self.send_discovery_notification(DiscoveryNotificationType::WriterUpdated {
              discovered_writer_data: dwd,
            });
          }
          Sample::Dispose(writer_guid) => {
            info!("Secure Dispose Writer {:?}", writer_guid);
            discovery_db_write(&self.discovery_db).remove_topic_writer(writer_guid);
            self.send_discovery_notification(DiscoveryNotificationType::WriterLost { writer_guid });
            self.send_participant_status(DomainParticipantStatusEvent::WriterLost {
              guid: writer_guid,
              reason: LostReason::Disposed,
            });
          }
        }
      }
    }
  }

  #[cfg(feature = "security")]
  fn on_secure_discovery_message_resend_triggered(&mut self) {
    if let Some(security) = self.security_opt.as_mut() {
      // Security is enabled
      security.resend_cached_secure_discovery_messages(
        &self.dcps_participant_stateless_message.writer,
        &self.dcps_participant_volatile_message_secure.writer,
      );

      // Reset timer for resending security messages
      self
        .cached_secure_discovery_messages_resend_timer
        .set_timeout(Self::CACHED_SECURE_DISCOVERY_MESSAGE_RESEND_PERIOD, ());
    }
  }

  pub fn participant_cleanup(&self) {
    let removed = discovery_db_write(&self.discovery_db).participant_cleanup();
    for (guid_prefix, reason) in removed {
      debug!("participant cleanup - timeout for {:?}", guid_prefix);
      self.send_discovery_notification(DiscoveryNotificationType::ParticipantLost { guid_prefix });
      self.send_participant_status(DomainParticipantStatusEvent::ParticipantLost {
        id: guid_prefix,
        reason,
      });
    }
  }

  pub fn topic_cleanup(&self) {
    discovery_db_write(&self.discovery_db).topic_cleanup();
  }

  pub fn sedp_publish_single_reader(&self, guid: GUID) {
    let db = discovery_db_read(&self.discovery_db);
    if let Some(reader_data) = db.get_local_topic_reader(guid) {
      if !reader_data
        .reader_proxy
        .remote_reader_guid
        .entity_id
        .kind()
        .is_user_defined()
      {
        // Only readers of user-defined topics are published to discovery
        return;
      }

      #[cfg(not(feature = "security"))]
      let do_nonsecure_write = true;

      #[cfg(feature = "security")]
      let do_nonsecure_write = if let Some(security) = self.security_opt.as_ref() {
        security.sedp_publish_single_reader(
          &self.dcps_subscription.writer,
          &self.dcps_subscriptions_secure.writer,
          reader_data,
        );
        false
      } else {
        true // No security configured
      };

      if do_nonsecure_write {
        match self
          .dcps_subscription
          .writer
          .write(reader_data.clone(), None)
        {
          Ok(()) => {
            debug!(
              "Published DCPSSubscription data on topic {}, reader guid {:?}, data {:?}",
              reader_data.subscription_topic_data.topic_name(),
              guid,
              reader_data,
            );
          }
          Err(e) => {
            error!(
              "Failed to publish DCPSSubscription data on topic {}, reader guid {:?}. Error: {e}",
              reader_data.subscription_topic_data.topic_name(),
              guid
            );
            // TODO: try again later?
          }
        }
      }
    } else {
      warn!("Did not find a local reader {guid:?}");
    }
  }

  pub fn sedp_publish_readers(&self) {
    let db = discovery_db_read(&self.discovery_db);
    let local_user_reader_guids = db
      .get_all_local_topic_readers()
      .filter(|p| {
        p.reader_proxy
          .remote_reader_guid
          .entity_id
          .kind()
          .is_user_defined()
      })
      .map(|drd| drd.reader_proxy.remote_reader_guid);

    for guid in local_user_reader_guids {
      self.sedp_publish_single_reader(guid);
    }
  }

  pub fn sedp_publish_single_writer(&self, guid: GUID) {
    let db = discovery_db_read(&self.discovery_db);
    if let Some(writer_data) = db.get_local_topic_writer(guid) {
      if !writer_data
        .writer_proxy
        .remote_writer_guid
        .entity_id
        .kind()
        .is_user_defined()
      {
        // Only writers of user-defined topics are published to discovery
        return;
      }

      #[cfg(not(feature = "security"))]
      let do_nonsecure_write = true;

      #[cfg(feature = "security")]
      let do_nonsecure_write = if let Some(security) = self.security_opt.as_ref() {
        security.sedp_publish_single_writer(
          &self.dcps_publication.writer,
          &self.dcps_publications_secure.writer,
          writer_data,
        );
        false
      } else {
        true // No security configured
      };

      if do_nonsecure_write {
        match self
          .dcps_publication
          .writer
          .write(writer_data.clone(), None)
        {
          Ok(()) => {
            debug!(
              "Published DCPSPublication data on topic {}, writer guid {:?}",
              writer_data.publication_topic_data.topic_name(),
              guid
            );
          }
          Err(e) => {
            error!(
              "Failed to publish DCPSPublication data on topic {}, writer guid {:?}. Error: {e}",
              writer_data.publication_topic_data.topic_name(),
              guid
            );
            // TODO: try again later?
          }
        }
      }
    } else {
      warn!("Did not find a local writer {guid:?}");
    }
  }

  pub fn sedp_publish_writers(&self) {
    let db: std::sync::RwLockReadGuard<'_, DiscoveryDB> = discovery_db_read(&self.discovery_db);
    let local_user_writer_guids = db
      .get_all_local_topic_writers()
      .filter(|p| {
        p.writer_proxy
          .remote_writer_guid
          .entity_id
          .kind()
          .is_user_defined()
      })
      .map(|drd| drd.writer_proxy.remote_writer_guid);

    for guid in local_user_writer_guids {
      self.sedp_publish_single_writer(guid);
    }
  }

  pub fn sedp_publish_topic(&self, topic_name: &str) {
    let db = discovery_db_read(&self.discovery_db);
    // We might have multiple topics with the same name (but different Qos etc..),
    // and the following call gets just one of them. Should we publish all of
    // them or is this enough?
    let topic_data = match db.get_topic(topic_name) {
      Some(data) => data,
      None => {
        warn!("Did not find topic data with topic name {topic_name}");
        return;
      }
    };

    // Only user-defined topics are published to discovery
    let is_user_defined = !topic_data.topic_name().starts_with("DCPS");
    if !is_user_defined {
      return;
    }

    match self.dcps_topic.writer.write(topic_data.clone(), None) {
      Ok(()) => {
        debug!("Published topic {topic_name} to DCPSTopic");
      }
      Err(e) => {
        error!("Failed to publish topic {topic_name} to DCPSTopic: {e}");
        // TODO: try again later?
      }
    }
  }

  pub fn subscriber_qos() -> QosPolicies {
    // The Subscriber QoS is specified in DDS Spec v1.4 Section
    // "2.2.5 Built-in Topics"
    QosPolicyBuilder::new()
      .durability(Durability::TransientLocal)
      .presentation(Presentation {
        access_scope: PresentationAccessScope::Topic,
        coherent_access: false,
        ordered_access: false,
      })
      .deadline(Deadline(Duration::INFINITE))
      .ownership(Ownership::Shared)
      .liveliness(Liveliness::Automatic {
        lease_duration: Duration::INFINITE,
      })
      .time_based_filter(TimeBasedFilter {
        minimum_separation: Duration::ZERO,
      })
      .reliability(Reliability::Reliable {
        max_blocking_time: Duration::from_std(StdDuration::from_millis(100)),
      })
      .destination_order(DestinationOrder::ByReceptionTimestamp)
      // Spec gives History KeepLast depth = 1, but we
      // use somewhat higher to avoid losing data at the receiver in case
      // it comes in bursts and there is some delay in Discovery processing.
      .history(History::KeepLast { depth: 4 })
      // TODO:
      // Spec says all resource limits should be "LENGTH_UNLIMITED",
      // but that may lead to memory exhaustion.
      //
      // .resource_limits(ResourceLimits { // TODO: Maybe lower limits would suffice?
      //   max_instances: std::i32::MAX,
      //   max_samples: std::i32::MAX,
      //   max_samples_per_instance: std::i32::MAX,
      // })
      .build()
  }

  pub fn publisher_qos() -> QosPolicies {
    // TODO: Check if this definition is correct (spec?)
    // Problem: DDS spec v1.4 Section 2.2.5 gives Subscriber QoS policies,
    // but does not mention publisher QoS for built-in topics.
    //
    //
    QosPolicyBuilder::new()
      .durability(Durability::TransientLocal)
      .presentation(Presentation {
        access_scope: PresentationAccessScope::Topic,
        coherent_access: false,
        ordered_access: false,
      })
      .deadline(Deadline(Duration::INFINITE))
      .ownership(Ownership::Shared)
      .liveliness(Liveliness::Automatic {
        lease_duration: Duration::INFINITE,
      })
      .time_based_filter(TimeBasedFilter {
        minimum_separation: Duration::ZERO,
      })
      .reliability(Reliability::Reliable {
        max_blocking_time: Duration::from_std(StdDuration::from_millis(100)),
      })
      .destination_order(DestinationOrder::ByReceptionTimestamp)
      // History must be different from Subscriber side, because otherwise
      // only the latest created Reder/Writer/Topic will be buffered and the older
      // ones forgotten.
      .history(History::KeepAll)
      // .resource_limits(ResourceLimits { // TODO: Maybe lower limits would suffice?
      //   max_instances: std::i32::MAX,
      //   max_samples: std::i32::MAX,
      //   max_samples_per_instance: std::i32::MAX,
      // })
      .build()
  }

  // This is (partially) gven in DDS Spec v1.4 Section 8.5.3.3.1
  // SPDPbuiltinParticipantWriter Table 8.79 - Attributes of the RTPS
  // StatelessWriter used by the SPDP at least that is is BestEffort.
  pub fn create_spdp_participant_qos() -> QosPolicies {
    QosPolicyBuilder::new()
      .reliability(Reliability::BestEffort)
      // Use depth=8 to avoid losing data when we receive notifications
      // faster than we can process.
      .history(History::KeepLast { depth: 8 })
      .build()
  }

  #[cfg(feature = "security")]
  pub fn create_participant_stateless_message_qos() -> QosPolicies {
    // See section 7.4.3 "New DCPSParticipantStatelessMessage builtin Topic" of the
    // Security spec
    QosPolicyBuilder::new()
      .reliability(Reliability::BestEffort) // Important!
      .history(History::KeepLast { depth: 1 })
      .build()
  }

  #[cfg(feature = "security")]
  pub fn create_participant_volatile_message_secure_qos() -> QosPolicies {
    // See Table 18  Non-default Qos policies for
    // BuiltinParticipantVolatileMessageSecureWriter of the Security spec
    QosPolicyBuilder::new()
      .reliability(Reliability::Reliable {
        max_blocking_time: Duration::from_std(StdDuration::from_millis(100)),
      })
      .history(History::KeepAll)
      .durability(Durability::Volatile)
      .build()
  }

  fn send_discovery_notification(&self, dntype: DiscoveryNotificationType) {
    match self.discovery_updated_sender.send(dntype) {
      Ok(_) => (),
      Err(e) => error!("Failed to send DiscoveryNotification {e:?}"),
    }
  }

  fn send_participant_status(&self, event: DomainParticipantStatusEvent) {
    self
      .participant_status_sender
      .try_send(event)
      .unwrap_or_else(|e| error!("Cannot report participant status: {e:?}"));
  }
}
*/

use crate::io_uring::timer::{Timer, timer_state};

struct Timers<T> {
    participant_cleanup: Timer<(), T>,
    topic_cleanup: Timer<(), T>,
    spdp_publish: Timer<(), T>,
    participant_messages: Timer<(), T>,
}

use crate::with_key::ReadState;

use crate::dds::key::Key;
use crate::with_key::datasample_cache::DataSampleCache;
use crate::rtps::writer::HistoryBuffer;

use crate::rtps::rtps_reader_proxy::RtpsReaderProxy;
use crate::rtps::rtps_writer_proxy::RtpsWriterProxy;

pub(crate) struct Cache<D: Keyed> {
    pub(crate) qos: QosPolicies,
    // read section
    pub(crate) reader_guid: GUID,
    topic: TopicCache,
    read: ReadState<<D as Keyed>::K>,
    datasample: DataSampleCache<D>,
    writer_proxies: BTreeMap<GUID, RtpsWriterProxy>,
    writer_match_count_total: i32,

    // write section

    pub(crate) writer_guid: GUID,
    sequence_number: i64,
    history_buffer: HistoryBuffer,
    reader_proxies: BTreeMap<GUID, RtpsReaderProxy>,
    matched_readers_count_total: i32,
    requested_incompatible_qos_count: i32,
}

use crate::dds::key::KeyHash;
use std::collections::BTreeMap;
use crate::with_key::{DeserializerAdapter, SerializerAdapter, DefaultDecoder};


use crate::dds::statusevents::CountWithChange;
use crate::{DataWriterStatus, DataReaderStatus};

impl <D: Keyed> Cache<D> {
    fn new(topic_name: &str, topic_type: &str, qos: QosPolicies, writer_guid: GUID, reader_guid: GUID) -> Self {
        use crate::TypeDesc;
        let qos_2 = qos.clone();
        Self {
            topic: TopicCache::new(topic_name.to_string(), TypeDesc::new(topic_type.to_string()), &qos),
            read: ReadState::new(),
            datasample: DataSampleCache::new(qos_2),
            qos,
            reader_guid,
            writer_proxies: BTreeMap::new(),
            writer_match_count_total: 0,

            writer_guid,
            sequence_number: 1,
            history_buffer: HistoryBuffer::new(topic_name.to_string()),
            reader_proxies: BTreeMap::new(),
            matched_readers_count_total: 0,
            requested_incompatible_qos_count: 0,
        }
    }

    fn deserialize<DA: DeserializerAdapter<D> + DefaultDecoder<D>>(timestamp: Timestamp, cc: &CacheChange, hash_to_key_map: &mut BTreeMap<KeyHash, <D as Keyed>::K>) -> ReadResult<DeserializedCacheChange<D>> {
        let decoder = DA::DECODER;

        match &cc.data_value {
          DDSData::Data {
            serialized_payload,
          } => {
            // what is our data serialization format (representation identifier) ?
            if let Some(recognized_rep_id) = DA::supported_encodings()
              .iter()
              .find(|r| **r == serialized_payload.representation_identifier)
            {
              match DA::from_bytes_with(&serialized_payload.value, *recognized_rep_id, decoder) {
                // Data update, decoded ok
                Ok(payload) => {
                  let p = Sample::Value(payload);
                    Self::update_hash_to_key_map(hash_to_key_map, &p);
                  Ok(DeserializedCacheChange::new(timestamp, cc, p))
                }
                Err(e) => Err(ReadError::Deserialization {
                  reason: format!(
                    "Failed to deserialize sample bytes: {},",
                    e,
                    /*
                    self.my_topic.name(),
                    self.my_topic.get_type()
                    */
                  ),
                }),
              }
            } else {
              info!(
                "Unknown representation id: {:?}, data = {:02x?}",
                serialized_payload.representation_identifier,
                /*
                self.my_topic.name(),
                self.my_topic.get_type(),
                */
                serialized_payload.value,
              );
              Err(ReadError::Deserialization {
                reason: format!(
                  "Unknown representation id {:?}",
                  serialized_payload.representation_identifier,
                  /*
                  self.my_topic.name(),
                  self.my_topic.get_type()
                  */
                ),
              })
            }
          }

          DDSData::DisposeByKey {
            key: ref serialized_key,
            ..
          } => {
            match DA::key_from_bytes_with(
              &serialized_key.value,
              serialized_key.representation_identifier,
              decoder,
            ) {
              Ok(key) => {
                let k = Sample::Dispose(key);
                Self::update_hash_to_key_map(hash_to_key_map, &k);
                Ok(DeserializedCacheChange::new(timestamp, cc, k))
              }
              Err(e) => Err(ReadError::Deserialization {
                reason: format!(
                  "Failed to deserialize key {}",
                  e,
                  /*
                  self.my_topic.name(),
                  self.my_topic.get_type()
                  */
                ),
              }),
            }
          }

          DDSData::DisposeByKeyHash { key_hash, .. } => {
            // The cache should know hash -> key mapping even if the sample
            // has been disposed or .take()n
            if let Some(key) = hash_to_key_map.get(&key_hash) {
              Ok(DeserializedCacheChange::new(
                timestamp,
                cc,
                Sample::Dispose(key.clone()),
              ))
            } else {
              Err(ReadError::UnknownKey {
                details: format!(
                  "Received dispose with unknown key hash: {:x?}",
                  key_hash,
                ),
              })
            }
          }
        } // match
    }

    fn serialize<SA: SerializerAdapter<D>>(&mut self, data: D, sender: &UDPSender, ring: &mut IoUring) -> WriteResult<(DDSData, WriteOptions, SequenceNumber), D> {
        // serialize
        let send_buffer = match SA::to_bytes(&data) {
          Ok(b) => b,
          Err(e) => {
            return Err(WriteError::Serialization {
              reason: format!("{e}"),
              data,
            })
          }
        };

        use crate::messages::submessages::elements::serialized_payload::SerializedPayload;
        let ddsdata = DDSData::new(SerializedPayload::new_from_bytes(SA::output_encoding(), send_buffer));

        let sequence_number = self.sequence_number;

        self.sequence_number += 1;

        // NOTE: manual liveliness assertions are not checked as all builtin livelinesses are
        // either automatic or none.
        //Ok((ddsdata, WriteOptions::from(None), sequence_number.into()))

        let cc = CacheChange::new(self.writer_guid, sequence_number.into(), WriteOptions::from(None), ddsdata);
        let timestamp = Timestamp::now();

        self.history_buffer.add_change(timestamp, cc);

        // assuming that all builtin writers are operating only in push mode
        // and that all builtin writers are broadcasting

        use crate::rtps::Message;
        if let Some(cc) = self.history_buffer.get_change(timestamp) {
            let msgs_to_send: Vec<Message> = vec![];

            use crate::structure::locator::Locator;
            use std::collections::BTreeSet;
            let mut sent_list = BTreeSet::<Locator>::new();

            macro_rules! send_unless_send_and_mark {
                ($locs:expr) => {
                    for loc in $locs.iter() {
                        if !sent_list.contains(&loc) {
                            todo!();
                            sent_list.insert(loc.clone());
                        } else {

                        }
                    }
                }
            }
            //TODO: update so Caches implements
            //  rtps::writer::update_reader_proxy()
            //  ^^ this was in dp_event_loop::update_participant
            //  rtps::reader::update_writer_proxy()
            //  ^^ dp_event_loop::update_participant
            //  rtps::writer::participant_lost
            //  ^^ dp_event_loop::remote_participant_lost()
            //  rtps::reader::participant_lost()
            //  ^^ dp_event_loop::remote_participant_lost()

            // NOTE: the update_participant fn in dp_event loop
            // is _only_ for builtin readers/writers.
            //
            // *remote_participant_lost() is for all readers and writers however.
            // ^^^ meaning that builtins also have to be passed.
            //
            // pasing a &mut Caches for discovery could work
            // then depending on the state either destructure it as Option<&mut Cache<..>>
            //
            // this was alreaady passed in from discovery so it should be fine.

            for msg in msgs_to_send {
                sent_list.clear();
                //self.send_message_to_readers(Multicast, msg, &mut self.readers.values())
                use speedy::{Endianness, Writable};
                let buf = msg.write_to_vec_with_ctx(Endianness::LittleEndian).unwrap();

                for reader in &mut self.reader_proxies.values_mut() {
                    match (reader.unicast_locator_list.iter().find(|l| Locator::is_udp(l)), reader.multicast_locator_list.iter().find(|l| Locator::is_udp(l))) {
                        (_, Some(_)) => {
                            sender.send_to_locator_list(&buf, &reader.multicast_locator_list, ring);
                            //send to multicast locator list
                        }
                        (Some(_), _) => {
                            sender.send_to_locator_list(&buf, &reader.unicast_locator_list, ring);
                            // send to unicast locator list
                        }
                        _ => warn!("no locators found for {reader:?}"),
                    }
                }
            }
        }
        todo!()
    }

      fn update_hash_to_key_map(
        hash_to_key_map: &mut BTreeMap<KeyHash, D::K>,
        deserialized: &Sample<D, D::K>,
      ) {
        let instance_key = match deserialized {
          Sample::Value(d) => d.key(),
          Sample::Dispose(k) => k.clone(),
        };
        hash_to_key_map.insert(instance_key.hash_key(false), instance_key);
      }

    pub(crate) fn update_reader_proxy(&mut self, reader_proxy: &RtpsReaderProxy) -> Option<(DataWriterStatus, DomainParticipantStatusEvent)> {
        let change = self.matched_reader_update(reader_proxy);

        if change > 0 {
            self.matched_readers_count_total += change;

            let writer_status = DataWriterStatus::PublicationMatched {
                total: CountWithChange::new(self.matched_readers_count_total, change),
                current: CountWithChange::new(self.reader_proxies.len() as i32, change),
                reader: reader_proxy.remote_reader_guid,
            };

            let participant_status = DomainParticipantStatusEvent::RemoteReaderMatched {
                local_writer: self.writer_guid,
                remote_reader: reader_proxy.remote_reader_guid,
            };
            Some((writer_status, participant_status))
        } else {
            None
        }
    }

    pub(crate) fn update_reader_proxy_with_qos(&mut self, reader_proxy: &RtpsReaderProxy, requested_qos: &QosPolicies) -> Option<(DataWriterStatus, DomainParticipantStatusEvent)> {
        if let Some(bad_policy_id) =  self.qos.compliance_failure_wrt(requested_qos) {

            let writer_status = DataWriterStatus::OfferedIncompatibleQos {
              count: CountWithChange::new(self.requested_incompatible_qos_count, 1),
              last_policy_id: bad_policy_id,
              reader: reader_proxy.remote_reader_guid,
              requested_qos: Box::new(requested_qos.clone()),
              offered_qos: Box::new(self.qos.clone()),
            };

            let domain_status = DomainParticipantStatusEvent::RemoteReaderQosIncompatible {
              local_writer: self.writer_guid,
              remote_reader: reader_proxy.remote_reader_guid,
              requested_qos: Box::new(requested_qos.clone()),
              offered_qos: Box::new(self.qos.clone()),
            };

            Some((writer_status, domain_status))
        } else {
            self.update_reader_proxy(reader_proxy)
        }
    }

    pub(crate) fn update_writer_proxy(&mut self, writer_proxy: RtpsWriterProxy) -> Option<(DataReaderStatus, DomainParticipantStatusEvent)> {
        let writer = writer_proxy.remote_writer_guid;

        let count_change = if let Some(prox) = self.writer_proxies.get_mut(&writer_proxy.remote_writer_guid) {
            prox.update_contents(writer_proxy);
            0
        } else {
            self.writer_proxies.insert(writer_proxy.remote_writer_guid, writer_proxy);
            1
        };

        if count_change > 0 {
            self.writer_match_count_total += count_change;

            let reader_status = DataReaderStatus::SubscriptionMatched {
                total: CountWithChange::new(self.writer_match_count_total, count_change),
                current: CountWithChange::new(self.writer_proxies.len() as i32, count_change),
                writer,
            };

            let participant_status = DomainParticipantStatusEvent::RemoteWriterMatched {
                local_reader: self.reader_guid,
                remote_writer: writer,
            };

            Some((reader_status, participant_status))
        } else {
            None
        }
    }

    fn matched_reader_update(&mut self, updated_reader_proxy: &RtpsReaderProxy) -> i32 {
        let mut new = 0;
        let is_volatile = self.qos.is_volatile();

        self
          .reader_proxies
          .entry(updated_reader_proxy.remote_reader_guid)
          .and_modify(|rp| rp.update(updated_reader_proxy))
          .or_insert_with(|| {
            new = 1;
            let mut new_proxy = updated_reader_proxy.clone();
            if is_volatile {
              // With Durabilty::Volatile QoS we won't send the sequence numbers which existed
              // before matching with this reader. Therefore we set the reader as pending GAP
              // for all existing sequence numbers
              new_proxy.set_pending_gap_up_to(self.history_buffer.last_change_sequence_number());
            }
            new_proxy
          });
        new
    }

    pub(crate) fn participant_lost(&mut self, guid_prefix: GuidPrefix) -> BuiltinParticipantLost {
        let lost_readers = self.reader_proxies.range(guid_prefix.range()).map(|(g, _)| *g).collect::<Vec<_>>();

        let lost_writers = self.writer_proxies.range(guid_prefix.range()).map(|(g, _)| *g).collect::<Vec<_>>();

        BuiltinParticipantLost {
            readers: lost_readers.into_iter(),
            writers: lost_writers.into_iter(),
        }
    }

    fn reader_lost(&mut self, guid: GUID) -> Option<DataWriterStatus> {
        if self.reader_proxies.remove(&guid).is_some() {
            Some(DataWriterStatus::PublicationMatched {
                total: CountWithChange::new(self.matched_readers_count_total, 0),
                current: CountWithChange::new(self.reader_proxies.len() as i32, -1),
                reader: guid,
              })
        } else {
            None
        }
    }

    fn writer_lost(&mut self, guid: GUID) -> Option<DataReaderStatus> {
        if self.writer_proxies.remove(&guid).is_some() {
            Some(DataReaderStatus::SubscriptionMatched {
                total: CountWithChange::new(self.writer_match_count_total, 0),
                current: CountWithChange::new(self.writer_proxies.len() as i32, -1),
                writer: guid,
              })
        } else {
            None
        }
    }

    fn handle_heartbeat_msg(&mut self, writer_guid: GUID, heartbeat: &Heartbeat, final_flag_set: bool, mr_state: &MessageReceiverState, udp_sender: &UDPSender, ring: &mut IoUring) -> bool {
        let Some(proxy) = self.writer_proxies.get_mut(&writer_guid) else {
            return false;
        };

        if heartbeat.first_sn < SequenceNumber::default() {
          warn!(
            "Writer {:?} advertised SequenceNumbers from {:?} to {:?}!",
            writer_guid, heartbeat.first_sn, heartbeat.last_sn
          );
        }

        if heartbeat.count <= proxy.received_heartbeat_count {
            return false;
        }

        proxy.received_heartbeat_count = heartbeat.count;

        // remove changes until first sn
        proxy.irrelevant_changes_up_to(heartbeat.first_sn);
        
        let marker_moved = self.topic.mark_reliably_received_before(writer_guid, proxy.all_ackable_before());

        if marker_moved {
            //TODO: notify cache change..?
        }

        let reader_id = self.reader_guid.entity_id;

        use crate::structure::sequence_number::SequenceNumberSet;
        use crate::messages::submessages::submessages::AckNack;
        use crate::messages::submessages::submessages::ACKNACK_Flags;
        use enumflags2::BitFlags;
        use crate::messages::submessages::submessages::NACKFRAG_Flags;
        use crate::messages::submessages::submessages::NackFrag;
        use crate::structure::sequence_number::FragmentNumberSet;
        use crate::structure::locator::Locator;
        use crate::messages::submessages::submessages::InfoDestination;

        let missing_seqnums = proxy.missing_seqnums(heartbeat.first_sn, heartbeat.last_sn);

        // Interpretation of final flag in RTPS spec
        // 8.4.2.3.1 Readers must respond eventually after receiving a HEARTBEAT with
        // final flag not set
        //
        // Upon receiving a HEARTBEAT Message with final flag not set, the Reader must
        // respond with an ACKNACK Message. The ACKNACK Message may acknowledge
        // having received all the data samples or may indicate that some data
        // samples are missing. The response may be delayed to avoid message storms.

        if !missing_seqnums.is_empty() || !final_flag_set {
          //let mut partially_received = Vec::new();
          // report of what we have.
          // We claim to have received all SNs before "base" and produce a set of missing
          // sequence numbers that are >= base.
          let reader_sn_state = match missing_seqnums.first() {
            Some(&first_missing) => {
              // Here we assume missing_seqnums are returned in order.
              // Limit the set to maximum that can be sent in acknack submessage.

              SequenceNumberSet::from_base_and_set(
                first_missing,
                &missing_seqnums
                  .iter()
                  .copied()
                  .take_while(|sn| sn < &(first_missing + SequenceNumber::new(256)))
                  .filter(|sn| {
                      true
                      //TODO: bring this back for messages
                      //todo!()
                      /*
                    if this.is_frag_partially_received(writer_guid, *sn) {
                      partially_received.push(*sn);
                      false
                    } else {
                      true
                    }
                    */
                  })
                  .collect(),
              )
            }

            // Nothing missing. Report that we have all we have.
            None => SequenceNumberSet::new_empty(proxy.all_ackable_before()),
          };

          let response_ack_nack = AckNack {
            reader_id,
            writer_id: heartbeat.writer_id,
            reader_sn_state,
            count: proxy.next_ack_nack_sequence_number(),
          };

          // Sanity check
          //
          // Wrong. This sanity check is invalid. The condition
          // ack_base > heartbeat.last_sn + 1
          // May be legitimately true, if there are some changes available, and a GAP
          // after that. E.g. HEARTBEAT 1..8 and GAP 9..10. Then acknack_base == 11
          // and 11 > 8 + 1.
          //
          //
          // if response_ack_nack.reader_sn_state.base() > heartbeat.last_sn +
          // SequenceNumber::new(1) {   error!(
          //     "OOPS! AckNack sanity check tripped: HEARTBEAT = {:?} ACKNACK = {:?}
          // missing_seqnums = {:?} all_ackable_before = {:?} writer={:?}",
          //     &heartbeat, &response_ack_nack, missing_seqnums,
          // writer_proxy.all_ackable_before(), writer_guid,   );
          // }

          // The acknack can be sent now or later. The rest of the RTPS message
          // needs to be constructed. p. 48
          let acknack_flags = BitFlags::<ACKNACK_Flags>::from_flag(ACKNACK_Flags::Endianness)
            | BitFlags::<ACKNACK_Flags>::from_flag(ACKNACK_Flags::Final);

          let nackfrag_flags = BitFlags::<NACKFRAG_Flags>::from_flag(NACKFRAG_Flags::Endianness);

          // send NackFrags, if any
          //let mut nackfrags = Vec::new();
          /* TODO: 
          for sn in partially_received {
            let count = proxy.next_ack_nack_sequence_number();
            let mut missing_frags = vec![];
            //TODO
            //let mut missing_frags = this.missing_frags_for(writer_guid, sn);
            let first_missing = missing_frags.next();
            if let Some(first) = first_missing {
              let missing_frags_set = std::iter::once(first).chain(missing_frags).collect(); // "undo" the .next() above
              let nf = NackFrag {
                reader_id,
                writer_id: proxy.remote_writer_guid.entity_id,
                writer_sn: sn,
                fragment_number_state: FragmentNumberSet::from_base_and_set(
                  first,
                  &missing_frags_set,
                ),
                count,
              };
              nackfrags.push(nf);
            } else {
              error!("The dog ate my missing fragments.");
              // Really, this should not happen, as we are above checking
              // that this SN is really partially (and not fully) received.
            }
          }
          */

          // Decide where should we send a reply, i.e. ACKNACK
          let reply_locators = match &*mr_state.unicast_reply_locator_list {
            [] | [Locator::Invalid] => &proxy.unicast_locator_list,
            //TODO: What is writer_proxy has an empty list?
            others => others,
          };

          /*
          if !nackfrags.is_empty() {
            this.send_nackfrags_to(
              nackfrag_flags,
              nackfrags,
              InfoDestination {
                guid_prefix: mr_state.source_guid_prefix,
              },
              reply_locators,
              writer_guid,
            );
          }
          */

          let acknack_msg = Self::create_acknack(self.reader_guid.prefix, acknack_flags, response_ack_nack, InfoDestination {
              guid_prefix: mr_state.source_guid_prefix,
            }, );

          use speedy::{Writable, Endianness};
          let bytes = acknack_msg.write_to_vec_with_ctx(Endianness::LittleEndian).unwrap();

          udp_sender.send_to_locator_list(&bytes, reply_locators, ring).unwrap();

          return true;
        }

        false
    }

    fn create_acknack(
        guid_prefix: GuidPrefix,
        flags: BitFlags<ACKNACK_Flags>,
        acknack: AckNack,
        info_dst: InfoDestination,
    ) -> Message {
        use crate::structure::sequence_number::SequenceNumberSet;
        use crate::messages::submessages::submessages::NACKFRAG_Flags;
        use crate::messages::submessages::submessages::NackFrag;
        use crate::structure::sequence_number::FragmentNumberSet;
        use crate::structure::locator::Locator;
        use crate::messages::submessages::submessages::INFODESTINATION_Flags;
        use crate::messages::header::Header;
        use crate::messages::protocol_id::ProtocolId;
        use crate::messages::protocol_version::ProtocolVersion;
        use crate::messages::vendor_id::VendorId;

        let infodst_flags =
          BitFlags::<INFODESTINATION_Flags>::from_flag(INFODESTINATION_Flags::Endianness);

        let mut message = Message::new(Header {
          protocol_id: ProtocolId::default(),
          protocol_version: ProtocolVersion::THIS_IMPLEMENTATION,
          vendor_id: VendorId::THIS_IMPLEMENTATION,
          guid_prefix: guid_prefix,
        });

        message.add_submessage(info_dst.create_submessage(infodst_flags));

        message.add_submessage(acknack.create_submessage(flags));
        message
    }

    fn send_preemptive_acknacks(&mut self, udp_sender: &UDPSender, ring: &mut IoUring) -> std::io::Result<()> {

        let flags = BitFlags::<ACKNACK_Flags>::from_flag(ACKNACK_Flags::Endianness);

        let reader_id = self.reader_guid.entity_id;

        for (_, writer_proxy) in self.writer_proxies.iter_mut().filter(|(_, p)| p.no_changes_received()) {
          let acknack_count = writer_proxy.next_ack_nack_sequence_number();
          let RtpsWriterProxy {
            remote_writer_guid,
            unicast_locator_list,
            ..
          } = writer_proxy;


          let acknack = Self::create_acknack(self.reader_guid.prefix, flags, AckNack {
              reader_id,
              writer_id: remote_writer_guid.entity_id,
              reader_sn_state: SequenceNumberSet::new_empty(SequenceNumber::new(1)),
              count: acknack_count,
          }, InfoDestination {
              guid_prefix: remote_writer_guid.prefix,
          })


          /*
          let acknack_msg = Self::create_acknack(self.reader_guid.prefix, acknack_flags, response_ack_nack, InfoDestination {
              guid_prefix: mr_state.source_guid_prefix,
            }, );

          use speedy::{Writable, Endianness};
          let bytes = acknack_msg.write_to_vec_with_ctx(Endianness::LittleEndian).unwrap();

          udp_sender.send_to_locator_list(&bytes, reply_locators, ring).unwrap();
          */



        }
        Ok(())
    }
}

use crate::messages::submessages::submessages::ACKNACK_Flags;
use enumflags2::BitFlags;
use crate::messages::submessages::submessages::AckNack;
use crate::messages::submessages::submessages::InfoDestination;
use crate::rtps::Message;

use crate::messages::submessages::submessages::Heartbeat;

pub(crate) struct BuiltinParticipantLost {
    readers: vec::IntoIter<GUID>,
    writers: vec::IntoIter<GUID>,
}

impl BuiltinParticipantLost {
    pub fn inner<'a, 'b, D: Keyed>(&'b mut self, cache: &'a mut Cache<D>) -> BuiltinParticipantLostInner<'a, 'b, D> {
        BuiltinParticipantLostInner::new(cache, self)
    }
}

pub(crate) struct BuiltinParticipantLostInner<'a, 'b, D: Keyed> {
    cache: &'a mut Cache<D>,
    participant_lost: &'b mut BuiltinParticipantLost,
}

impl <'a, 'b, D: Keyed> BuiltinParticipantLostInner<'a, 'b, D> {
    fn new(
            cache: &'a mut Cache<D>,
            participant_lost: &'b mut BuiltinParticipantLost,
        ) -> Self {
        Self {
            cache,
            participant_lost,
        }
    }
}

impl <D: Keyed> Iterator for BuiltinParticipantLostInner<'_, '_, D> {
    type Item = (DataStatus, GUID);

    fn next(&mut self) -> Option<Self::Item> {
        while let Some(reader) = self.participant_lost.readers.next() {
            if let Some(lost) = self.cache.reader_lost(reader) {
                return Some((DataStatus::Writer(lost), reader));
            }
        }

        while let Some(writer) = self.participant_lost.writers.next() {
            if let Some(lost) = self.cache.writer_lost(writer) {
                return Some((DataStatus::Reader(lost), writer))
            }
        }
        None
    }
}

use crate::io_uring::rtps::DataStatus;

use crate::Keyed;

pub(crate) struct Caches {
    pub(crate) publications: Cache<DiscoveredWriterData>,
    pub(crate) topics: Cache<DiscoveredTopicData>,
    pub(crate) participants: Cache<SpdpDiscoveredParticipantData>,
    pub(crate) subscriptions: Cache<DiscoveredReaderData>,
    pub(crate) participant_messages: Cache<ParticipantMessageData>,
}

impl Caches {
    // used if theres no 
    fn subscriber_qos() -> QosPolicies {

    // The Subscriber QoS is specified in DDS Spec v1.4 Section
    // "2.2.5 Built-in Topics"
    QosPolicyBuilder::new()
      .durability(Durability::TransientLocal)
      .presentation(Presentation {
        access_scope: PresentationAccessScope::Topic,
        coherent_access: false,
        ordered_access: false,
      })
      .deadline(Deadline(Duration::INFINITE))
      .ownership(Ownership::Shared)
      .liveliness(Liveliness::Automatic {
        lease_duration: Duration::INFINITE,
      })
      .time_based_filter(TimeBasedFilter {
        minimum_separation: Duration::ZERO,
      })
      .reliability(Reliability::Reliable {
        max_blocking_time: Duration::from_std(StdDuration::from_millis(100)),
      })
      .destination_order(DestinationOrder::ByReceptionTimestamp)
      // Spec gives History KeepLast depth = 1, but we
      // use somewhat higher to avoid losing data at the receiver in case
      // it comes in bursts and there is some delay in Discovery processing.
      .history(History::KeepLast { depth: 4 })
      // TODO:
      // Spec says all resource limits should be "LENGTH_UNLIMITED",
      // but that may lead to memory exhaustion.
      //
      // .resource_limits(ResourceLimits { // TODO: Maybe lower limits would suffice?
      //   max_instances: std::i32::MAX,
      //   max_samples: std::i32::MAX,
      //   max_samples_per_instance: std::i32::MAX,
      // })
      .build()
    }

    fn participant_message_qos() -> QosPolicies {
        QosPolicies {
            durability: Some(Durability::TransientLocal),
            presentation: None,
            deadline: None,
            latency_budget: None,
            ownership: None,
            liveliness: None,
            time_based_filter: None,
            reliability: Some(Reliability::Reliable {
              max_blocking_time: Duration::ZERO,
            }),
            destination_order: None,
            history: Some(History::KeepLast { depth: 1 }),
            resource_limits: None,
            lifespan: None,
            #[cfg(feature = "security")]
            property: None,
          }
    }

    fn spdp_participant_qos() -> QosPolicies {
        QosPolicyBuilder::new()
          .reliability(Reliability::BestEffort)
          // Use depth=8 to avoid losing data when we receive notifications
          // faster than we can process.
          .history(History::KeepLast { depth: 8 })
          .build()
    }

    fn new(guid_prefix: GuidPrefix) -> Self {
        use crate::TypeDesc;

        Self {
            publications: Cache::new(builtin_topic_names::DCPS_PUBLICATION, builtin_topic_type_names::DCPS_PUBLICATION, Self::subscriber_qos(), GUID::new(guid_prefix, EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER), GUID::new(guid_prefix, EntityId::SEDP_BUILTIN_PUBLICATIONS_READER)),
            topics: Cache::new(builtin_topic_names::DCPS_TOPIC, builtin_topic_type_names::DCPS_TOPIC, Self::subscriber_qos(), GUID::new(guid_prefix, EntityId::SEDP_BUILTIN_TOPIC_WRITER), GUID::new(guid_prefix, EntityId::SEDP_BUILTIN_TOPIC_READER)),
            participants: Cache::new(builtin_topic_names::DCPS_PARTICIPANT, builtin_topic_type_names::DCPS_PARTICIPANT, Self::spdp_participant_qos(), GUID::new(guid_prefix, EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER), GUID::new(guid_prefix, EntityId::SPDP_BUILTIN_PARTICIPANT_READER)),
            subscriptions: Cache::new(builtin_topic_names::DCPS_SUBSCRIPTION, builtin_topic_type_names::DCPS_SUBSCRIPTION, Self::subscriber_qos(), GUID::new(guid_prefix, EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER), GUID::new(guid_prefix, EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_READER)),
            participant_messages: Cache::new(builtin_topic_names::DCPS_PARTICIPANT_MESSAGE, builtin_topic_type_names::DCPS_PARTICIPANT_MESSAGE, Self::participant_message_qos(), GUID::new(guid_prefix, EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER), GUID::new(guid_prefix, EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_READER))
        }
    }

    fn topic_cache_from_entity_id(&mut self, entity_id: EntityId) -> &mut TopicCache {
        match entity_id {
            EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER => &mut self.publications.topic,
            EntityId::SEDP_BUILTIN_TOPIC_WRITER => &mut self.topics.topic,
            EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER => &mut self.participants.topic,
            EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER => &mut self.subscriptions.topic,
            EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER => (&mut self.participant_messages.topic),
            _ => unreachable!(),
        }
    }

    fn update_reader_state(&mut self, entity_id: EntityId, instant: Timestamp, writer_guid: GUID, sequence_number: SequenceNumber) {
        match entity_id {
            EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER => {
                let state = &mut self.publications.read;
                state.last_read_sn.insert(writer_guid, sequence_number);
                state.latest_instant = instant;
            }
            EntityId::SEDP_BUILTIN_TOPIC_WRITER => {
                let state = &mut self.topics.read;
                state.last_read_sn.insert(writer_guid, sequence_number);
                state.latest_instant = instant;
            }
            EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER => {
                let state = &mut self.participants.read;
                state.last_read_sn.insert(writer_guid, sequence_number);
                state.latest_instant = instant;
            }
            EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER => {
                let state = &mut self.subscriptions.read;
                state.last_read_sn.insert(writer_guid, sequence_number);
                state.latest_instant = instant;
            }
            EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER => {
                let state = &mut self.participant_messages.read;
                state.last_read_sn.insert(writer_guid, sequence_number);
                state.latest_instant = instant;
            }
            _ => unreachable!(),
        }
    }

    fn populate_changes(&mut self, entity_id: EntityId, is_reliable: bool) {
        let (mut latest_instant, last_read_sn, topic_cache) = match entity_id {
            EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER => {
                let ReadState {
                    ref mut last_read_sn,
                    latest_instant,
                    ..
                } = self.publications.read;
                let topic = &mut self.publications.topic;
                (latest_instant, last_read_sn, topic)
            }
            EntityId::SEDP_BUILTIN_TOPIC_WRITER => {
                let ReadState {
                    ref mut last_read_sn,
                    latest_instant,
                    ..
                } = self.topics.read;
                let topic = &mut self.topics.topic;
                (latest_instant, last_read_sn, topic)
            }
            EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER => {
                let ReadState {
                    ref mut last_read_sn,
                    latest_instant,
                    ..
                } = self.participants.read;
                let topic = &mut self.participants.topic;
                (latest_instant, last_read_sn, topic)
            }
            EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER => {
                let ReadState {
                    ref mut last_read_sn,
                    latest_instant,
                    ..
                } = self.subscriptions.read;
                let topic = &mut self.subscriptions.topic;
                (latest_instant, last_read_sn, topic)
            }
            EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER => {
                let ReadState {
                    ref mut last_read_sn,
                    latest_instant,
                    ..
                } = self.participant_messages.read;
                let topic = &mut self.participant_messages.topic;
                (latest_instant, last_read_sn, topic)
            }
            _ => unreachable!(),
        };

        let changes = if is_reliable {
          topic_cache.get_changes_in_range_reliable(last_read_sn)
        } else {
          topic_cache.get_changes_in_range_best_effort(latest_instant, Timestamp::now())
        };


        use crate::serialization::pl_cdr_adapters::PlCdrDeserializerAdapter;
        use crate::CDRDeserializerAdapter;

        let mut reliable_reading = None;

        // handle changes
        for (timestamp, change) in changes {
            latest_instant = core::cmp::max(latest_instant, timestamp);
            reliable_reading = Some((change.writer_guid, change.sequence_number));

            macro_rules! deserialize_and_populate_cache {
                ($namespace:expr, $adapter:ty) => {
                    let key_map = &mut $namespace.read.hash_to_key_map;

                    let deserialized = Cache::deserialize::<$adapter>(timestamp, change, key_map);

                    if matches!(deserialized, Err(ReadError::UnknownKey { .. })) {
                        continue;
                    }

                    //TODO: could aggregate the error here.
                    match deserialized {
                        Ok(deserialized) => {
                            $namespace.datasample.fill_from_deserialized_cache_change(deserialized);
                        }
                        Err(e) => warn!("{e:?}"),
                    }
                }
            }

            match entity_id {
                EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER => {
                    deserialize_and_populate_cache!(self.publications, PlCdrDeserializerAdapter<DiscoveredWriterData>);
                }
                EntityId::SEDP_BUILTIN_TOPIC_WRITER => {
                    deserialize_and_populate_cache!(self.topics, PlCdrDeserializerAdapter<DiscoveredTopicData>);
                }
                EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER => {
                    deserialize_and_populate_cache!(self.participants, PlCdrDeserializerAdapter<SpdpDiscoveredParticipantData>);
                }
                EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER => {
                    deserialize_and_populate_cache!(self.subscriptions, PlCdrDeserializerAdapter<DiscoveredReaderData>);
                }
                EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER => {
                    deserialize_and_populate_cache!(self.participant_messages, CDRDeserializerAdapter<ParticipantMessageData>);
                }
                _ => unreachable!(),
            }
        }

        if let Some((guid, sn)) = reliable_reading {
            self.update_reader_state(entity_id, latest_instant, guid, sn);
        }
    }

    fn distribute_changes<'a, 'b>(&'a mut self, entity_id: EntityId, discovery_db: &'b mut DiscoveryDB) -> Option<DiscoveredKind> {
        let read_condition = ReadCondition::not_read();
        Some(match entity_id {
            EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER => {
                let cache = &mut self.publications.datasample;
                let keys = cache.select_keys_for_access(read_condition);
                let result = cache.take_by_keys(&keys);
                
                DiscoveredKind::Writer(DiscoveredIter::new(result))
            }
            EntityId::SEDP_BUILTIN_TOPIC_WRITER => {
                let cache = &mut self.topics.datasample;
                let keys = cache.select_keys_for_access(read_condition);
                let result = cache.take_by_keys(&keys);
                DiscoveredKind::Topic(TopicDiscoveryIter::new(result))
            }
            EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER => {
                let cache = &mut self.participants.datasample;
                let keys = cache.select_keys_for_access(read_condition);
                let result = cache.take_by_keys(&keys);

                let domain_guid = discovery_db.my_guid.prefix;

                DiscoveredKind::Participant(ParticipantDiscoveryIter::new(domain_guid, result))
            }
            EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER => {
                let cache = &mut self.subscriptions.datasample;
                let keys = cache.select_keys_for_access(read_condition);
                let result = cache.take_by_keys(&keys);

                DiscoveredKind::Reader(DiscoveredIter::new(result))
            }
            EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER => {
                let cache = &mut self.participant_messages.datasample;
                let keys = cache.select_keys_for_access(read_condition);
                let result = cache.read_by_keys(&keys);

                //receive_participant_message()
                for sample in result {
                    match sample.value {
                        Sample::Value(sub_data) => {
                            discovery_db.update_lease_duration(sub_data);
                        }
                        Sample::Dispose(reader_key) => {
                            println!("lost: {reader_key:?}")
                        }
                    }
                }
                return None;
            }
            _ => unreachable!(),
        })
    }

    fn handle_heartbeat_msg(&mut self, writer_guid: GUID, heartbeat: &Heartbeat, final_flag_set: bool, mr_state: &MessageReceiverState, udp_sender: &UDPSender, ring: &mut IoUring) -> bool {
        match writer_guid.entity_id {
            EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER => {
                self.publications.handle_heartbeat_msg(writer_guid, heartbeat, final_flag_set, mr_state, udp_sender, ring)
            }
            EntityId::SEDP_BUILTIN_TOPIC_WRITER => {
                self.topics.handle_heartbeat_msg(writer_guid, heartbeat, final_flag_set, mr_state, udp_sender, ring)
            }
            EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER => {
                self.participants.handle_heartbeat_msg(writer_guid, heartbeat, final_flag_set, mr_state, udp_sender, ring)
            }
            EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER => {
                self.subscriptions.handle_heartbeat_msg(writer_guid, heartbeat, final_flag_set, mr_state, udp_sender, ring)
            }
            EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER => {
                self.participant_messages.handle_heartbeat_msg(writer_guid, heartbeat, final_flag_set, mr_state, udp_sender, ring)
            }
            _ => unreachable!(),
        }
    }

    pub(crate) fn send_preemptive_acknacks(&mut self, udp_sender: &UDPSender, ring: &mut IoUring) -> std::io::Result<()> {
        todo!()
    }
}

/*
struct DiscoveredReaders<'a, 'b> {
    
}
*/

pub(crate) struct DiscoveredData<'a, 'b, D: Keyed> {
    pub discovery_db: &'a mut DiscoveryDB,
    discovered: &'b mut std::vec::IntoIter<DataSample<D>>
}

impl <'a, 'b, D: Keyed> DiscoveredData<'a, 'b, D> {
    fn new( discovery_db: &'a mut DiscoveryDB, discovered: &'b mut std::vec::IntoIter<DataSample<D>>) -> Self {
        Self {
            discovery_db,
            discovered,
        }
    }
}

enum RediscoveredState {
    Topic(std::vec::IntoIter<DataSample<DiscoveredTopicData>>, Option<TopicDiscoveryState>),
    Reader(std::vec::IntoIter<DataSample<DiscoveredReaderData>>),
    Writer(std::vec::IntoIter<DataSample<DiscoveredWriterData>>),
    Done,
}

pub(crate) struct ParticipantDiscoveryIter {
    participant_guid_prefix: GuidPrefix,
    participant_data: vec::IntoIter<DataSample<SpdpDiscoveredParticipantData>>,
    current: Option<(RediscoveredState, GuidPrefix)>
}

impl  ParticipantDiscoveryIter {
    fn new(
        participant_guid_prefix: GuidPrefix,
        participant_data: Vec<DataSample<SpdpDiscoveredParticipantData>>,
    ) -> Self {
        Self {
            participant_guid_prefix,
            participant_data: participant_data.into_iter(),
            current: None,
        }
    }

    fn inner<'a, 'b>(&mut self, discovery_db: &'a mut DiscoveryDB, discovery: &'b mut Discovery2<timer_state::Init>) -> ParticipantDiscoveryIterInner<'a, 'b, '_> {
        ParticipantDiscoveryIterInner {
            participant_guid_prefix: &mut self.participant_guid_prefix,
            participant_data: &mut self.participant_data,
            topic_data: &mut discovery.caches.topics.datasample,
            reader_data: &mut discovery.caches.subscriptions.datasample,
            writer_data: &mut discovery.caches.publications.datasample,
            discovery_db,
            current: &mut self.current,
        }
    }
}


pub struct Discovered<'a, 'b, 'c> {
    pub(crate) discovery: &'a mut Discovery2<timer_state::Init>,
    pub(crate) discovery_db: &'b mut DiscoveryDB,
    kind: &'c mut DiscoveredKind,
}

impl <'a, 'b, 'c> Discovered<'a, 'b, 'c> {
    pub(crate) fn new(
    discovery: &'a mut Discovery2<timer_state::Init>,
    discovery_db: &'b mut DiscoveryDB,
    kind: &'c mut DiscoveredKind) -> Self {
        Self {
            discovery,
            discovery_db,
            kind
        }
    }
}

pub enum DiscoveredKind {
    Participant(ParticipantDiscoveryIter),
    Topic(TopicDiscoveryIter),
    Reader(DiscoveredIter<DiscoveredReaderData>),
    Writer(DiscoveredIter<DiscoveredWriterData>),
}

impl Iterator for Discovered<'_, '_, '_> {
    type Item = (DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);

    fn next(&mut self) -> Option<Self::Item> {
        match &mut self.kind {
            DiscoveredKind::Participant(p) => p.inner(&mut self.discovery_db, &mut self.discovery).next(),
            DiscoveredKind::Topic(t) => t.inner(&mut self.discovery_db).next(),
            DiscoveredKind::Reader(r) => r.inner(&mut self.discovery_db).next(),
            DiscoveredKind::Writer(w) => w.inner(&mut self.discovery_db).next(),
        }
    }
}

/*
impl Iterator for Discovered<'_, '_> {
    type Item = (DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);

    fn next(&mut self) -> Option<Self::Item> {
        match self {
            Self::Participant(p) => p.next(),
            Self::Topic(t) => t.next(),
            Self::Reader(r) => r.next(),
            Self::Writer(w) => w.next(),
        }
    }
}
*/



struct ParticipantDiscoveryIterInner<'a, 'b, 'c> {
    participant_guid_prefix: &'c GuidPrefix,
    discovery_db: &'a mut DiscoveryDB,
    participant_data: &'c mut vec::IntoIter<DataSample<SpdpDiscoveredParticipantData>>,
    topic_data: &'b mut DataSampleCache<DiscoveredTopicData>,
    reader_data: &'b mut DataSampleCache<DiscoveredReaderData>,
    writer_data: &'b mut DataSampleCache<DiscoveredWriterData>,
    current: &'c mut Option<(RediscoveredState, GuidPrefix)>
}

impl <'a, 'b, 'c, 'd> ParticipantDiscoveryIterInner<'a, 'b, 'c> {
    fn new(
        participant_guid_prefix: &'c GuidPrefix,
        discovery_db: &'a mut DiscoveryDB,
        participant_data: &'c mut vec::IntoIter<DataSample<SpdpDiscoveredParticipantData>>,
        topic_data: &'b mut DataSampleCache<DiscoveredTopicData>,
        reader_data: &'b mut DataSampleCache<DiscoveredReaderData>,
        writer_data: &'b mut DataSampleCache<DiscoveredWriterData>,
        current: &'c mut Option<(RediscoveredState, GuidPrefix)>
        ) -> Self {
        Self {
            participant_guid_prefix,
            discovery_db,
            participant_data,
            topic_data,
            reader_data,
            writer_data,
            current,
        }
    }

    fn advance_state<D: Keyed>(cache: &mut DataSampleCache<D>, mut f: impl FnMut(&DataSample<D>) -> bool) -> std::vec::IntoIter<DataSample<D>> {
        let read_condition = ReadCondition::any();
        let keys = cache.select_keys_for_access(read_condition);
        let result = cache.take_by_keys(&keys);

        let filtered = result.into_iter().filter(f).collect::<Vec<_>>();
        filtered.into_iter()
    }

    fn advance_to_readers(readers: &mut DataSampleCache<DiscoveredReaderData>, guid: GuidPrefix) -> std::vec::IntoIter<DataSample<DiscoveredReaderData>> {
        Self::advance_state(readers, |reader| match &reader.value {
            Sample::Value(r) => r.reader_proxy.remote_reader_guid.prefix == guid,
            Sample::Dispose(reader_key) => reader_key.0.prefix == guid,
        })
    }

    fn advance_to_writers(writers: &mut DataSampleCache<DiscoveredWriterData>, guid: GuidPrefix) -> std::vec::IntoIter<DataSample<DiscoveredWriterData>> {
        Self::advance_state(writers, |writer| match &writer.value {
            Sample::Value(r) => r.writer_proxy.remote_writer_guid.prefix == guid,
            Sample::Dispose(writer_key) => writer_key.0.prefix == guid,
        })
    }
}

impl Iterator for ParticipantDiscoveryIterInner<'_, '_, '_> {
    type Item = (DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);
    fn next(&mut self) -> Option<Self::Item> {
        // this is the only way to make the compiler happy.
        // something about the invariance of the lifetimes.
        match &mut self.current {
            None | Some((RediscoveredState::Done, _)) => (),
            Some((RediscoveredState::Topic(topics, state), guid)) => {
                if let Some(ret) = TopicDiscoveryIterInner::new(self.discovery_db, topics, state).next() {
                    return Some(ret);
                }

                let mut readers = Self::advance_to_readers(self.reader_data, *guid);

                if let Some(ret) = DiscoveredData::new(self.discovery_db, &mut readers).next() {
                    let state = RediscoveredState::Reader(readers);
                    *self.current = Some((state, *guid));
                    return Some(ret);
                }
                drop(readers);

                let mut writers = Self::advance_to_writers(self.writer_data, *guid);

                if let Some(ret) = DiscoveredData::new(self.discovery_db, &mut writers).next() {
                    let state = RediscoveredState::Writer(writers);
                    *self.current = Some((state, *guid));
                    return Some(ret);
                }
                drop(writers);
            }
            Some((RediscoveredState::Reader(readers), guid)) => {
                if let Some(ret) = DiscoveredData::new(self.discovery_db, readers).next() {
                    return Some(ret);
                }

                let mut writers = Self::advance_to_writers(self.writer_data, *guid);

                if let Some(ret) = DiscoveredData::new(self.discovery_db, &mut writers).next() {
                    let state = RediscoveredState::Writer(writers);
                    *self.current = Some((state, *guid));
                    return Some(ret);
                }
                drop(writers);
            }
            Some((RediscoveredState::Writer(writers), guid)) => {
                if let Some(ret) = DiscoveredData::new(self.discovery_db, writers).next() {
                    return Some(ret);
                }
            }
        }

        let (guid, discovery_notification, status_event) = DiscoveredData::new(self.discovery_db, &mut self.participant_data).next()?;

        match guid {
            // remote participant that may have been discovered earlier,
            // re iterate over any existing caches.
            Some(guid) if guid != *self.participant_guid_prefix => {
                let topics = Self::advance_state(self.topic_data, |topic| topic.sample_info.writer_guid().prefix == guid);

                let state = RediscoveredState::Topic(topics, None);
                *self.current = Some((state, guid));
            }
            _ => *self.current = None,
        }
        Some((discovery_notification, status_event))

    }
}


impl Iterator for DiscoveredData<'_, '_, SpdpDiscoveredParticipantData> {
    type Item = (Option<GuidPrefix>, DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);

    fn next(&mut self) -> Option<Self::Item> {
        let disc = self.discovered.next()?.value;

        match disc {
            Sample::Value(participant_data) => {
                let was_new = self.discovery_db.update_participant(&participant_data);
                let guid_prefix = participant_data.participant_guid.prefix;
                let discovery_notification = DiscoveryNotificationType::ParticipantUpdated { guid_prefix };

                let participant_status = if was_new {
                    Some(DomainParticipantStatusEvent::ParticipantDiscovered {
                        dpd: (&participant_data).into(),
                    })
                } else {
                    None
                };

                Some((Some(guid_prefix), discovery_notification, participant_status))
            }
            Sample::Dispose(participant_guid) => {
                let guid_prefix = participant_guid.0.prefix;
                self.discovery_db.remove_participant(guid_prefix, true);
                Some((None, DiscoveryNotificationType::ParticipantLost { guid_prefix }, Some(DomainParticipantStatusEvent::ParticipantLost { id: guid_prefix, reason: LostReason::Disposed } )))
            }
        }
    }
}

pub(crate) struct DiscoveredIter<D: Keyed> {
    data: vec::IntoIter<DataSample<D>>,
}

impl <D: Keyed> DiscoveredIter<D> {
    fn new(data: Vec<DataSample<D>>) -> Self {
        Self {
            data: data.into_iter(),
        }
    }

    fn inner<'a>(&mut self, discovery_db: &'a mut DiscoveryDB) -> DiscoveredData<'a, '_, D> {
        DiscoveredData::new(discovery_db, &mut self.data)
    }
}

impl Iterator for DiscoveredData<'_, '_, DiscoveredReaderData> {
    type Item = (DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);

    fn next(&mut self) -> Option<Self::Item> {
        let discovered = self.discovered.next()?.value;

        match discovered.map_dispose(|g| g.0) {
            Sample::Value(sub) => {
                let (discovered_reader_data, participant_status) = self.discovery_db.update_subscription(&sub);

                let discovery_notification = DiscoveryNotificationType::ReaderUpdated {
                    discovered_reader_data,
                };

                Some((discovery_notification, participant_status))
            }
            Sample::Dispose(reader_key) => {
                self.discovery_db.remove_topic_reader(reader_key);

                let discovery_notification = DiscoveryNotificationType::ReaderLost {
                    reader_guid: reader_key,
                };

                let participant_status = DomainParticipantStatusEvent::ReaderLost {
                    guid: reader_key,
                    reason: LostReason::Disposed,
                };
                Some((discovery_notification, Some(participant_status)))
            }
        }
    }
}

impl Iterator for DiscoveredData<'_, '_, DiscoveredWriterData> {
    type Item = (DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);
    
    fn next(&mut self) -> Option<Self::Item> {
        let discovered = self.discovered.next()?.value;

        match discovered.map_dispose(|g| g.0) {
            Sample::Value(discovered) => {
                let (discovered_writer_data, participant_status) = self.discovery_db.update_publication(&discovered);

                let discovery_notification = DiscoveryNotificationType::WriterUpdated {
                    discovered_writer_data,
                };
                Some((discovery_notification, participant_status))
            }
            Sample::Dispose(writer_key) => {
                self.discovery_db.remove_topic_writer(writer_key);

                let discovery_notification = DiscoveryNotificationType::WriterLost {
                    writer_guid: writer_key,
                };
                let participant_status = DomainParticipantStatusEvent::WriterLost {
                    guid: writer_key,
                    reason: LostReason::Disposed,
                };
                Some((discovery_notification, Some(participant_status)))
            }
        }
    }
}

//wrapper for DiscoveredData<'a, DiscoveredTopicData>
//to be able to iterate over the updated readers/writers associated with the topic.
//if there are no readers/writers for a topic then a status event will not be emitted.
use std::vec;

pub(crate) struct TopicDiscoveryIter {
    topic_data: vec::IntoIter<DataSample<DiscoveredTopicData>>,
    state: Option<TopicDiscoveryState>,
}

impl TopicDiscoveryIter {
    fn new(topic_data: Vec<DataSample<DiscoveredTopicData>>) -> Self {
        Self {
            topic_data: topic_data.into_iter(),
            state: None,
        }
    }

    fn inner<'a>(&mut self, discovery_db: &'a mut DiscoveryDB) -> TopicDiscoveryIterInner<'a, '_> {
        TopicDiscoveryIterInner {
            current: &mut self.state,
            discovery_db,
            topic_data: &mut self.topic_data,
        }
    }
}

struct TopicDiscoveryState {
    discovered_readers: vec::IntoIter<DiscoveredReaderData>,
    discovered_writers: vec::IntoIter<DiscoveredWriterData>,
}

impl TopicDiscoveryState {
    fn new(
            discovered_readers: vec::IntoIter<DiscoveredReaderData>,
            discovered_writers: vec::IntoIter<DiscoveredWriterData>,
        ) -> Self {

        Self {
            discovered_readers,
            discovered_writers,
        }
    }


    fn take_item(&mut self) -> Option<DiscoveryNotificationType> {
        if let Some(notification) = if let Some(discovered_reader_data) = self.discovered_readers.next() {
            Some(DiscoveryNotificationType::ReaderUpdated {discovered_reader_data})
        } else if let Some(discovered_writer_data) = self.discovered_writers.next() {
            Some(DiscoveryNotificationType::WriterUpdated {discovered_writer_data})
        } else {
            None
        } {
            Some(notification)
        } else {
            None
        }
    }
}

struct TopicDiscoveryIterInner<'a, 'b> {
    discovery_db: &'a mut DiscoveryDB,
    topic_data: &'b mut vec::IntoIter<DataSample<DiscoveredTopicData>>,
    current: &'b mut Option<TopicDiscoveryState>,
}

impl <'a, 'b> TopicDiscoveryIterInner<'a, 'b> {
    fn new(
        discovery_db: &'a mut DiscoveryDB,
        topic_data: &'b mut vec::IntoIter<DataSample<DiscoveredTopicData>>,
        current: &'b mut Option<TopicDiscoveryState>,
    ) -> Self {
        Self {
            discovery_db,
            topic_data,
            current,
        }
    }
}

impl Iterator for TopicDiscoveryIterInner<'_, '_> {
    type Item = (DiscoveryNotificationType, Option<DomainParticipantStatusEvent>);

    fn next(&mut self) -> Option<Self::Item> {
        if let Some(state) = self.current.as_mut() {
            if let Some(ret) = state.take_item() {
                return Some((ret, None));
            }
        }

        let (topic_data, writer, status_event) = DiscoveredData::new(self.discovery_db, &mut self.topic_data).next()?;

        let readers = self.discovery_db.readers_on_topic_and_participant(topic_data.topic_name(), writer);

        let writers = self.discovery_db.writers_on_topic_and_participant(topic_data.topic_name(), writer);

        *self.current = Some(TopicDiscoveryState::new(readers.into_iter(), writers.into_iter()));

        Some((DiscoveryNotificationType::TopicDiscovered, status_event))
    }
}

impl Iterator for DiscoveredData<'_, '_, DiscoveredTopicData> {
    type Item = (DiscoveredTopicData, GuidPrefix, Option<DomainParticipantStatusEvent>);
    fn next(&mut self) -> Option<Self::Item> {
        let discovered = self.discovered.next()?;

        match discovered.value {
            Sample::Value(topic_data) => {
                let writer = discovered.sample_info.writer_guid();
                let status_event = self.discovery_db.update_topic_data(&topic_data, writer, 
              DiscoveredVia::Topic,
);
                Some((topic_data, writer.prefix, status_event))
            }
            Sample::Dispose(key) => {
                warn!("not implemented");
                None
            }
        }
    }
}

// DomainParticipantStatusEvent is for the user to listen in on the domain participant (wow)
// DiscoveryNotificationType is used in the DpEventLoop (now Domain) to update connections (and
// also send some DomainParticipantStatusEvent's)


impl Timers<timer_state::Uninit> {
    const PARTICIPANT_CLEANUP_PERIOD: StdDuration = StdDuration::from_secs(2);
    const TOPIC_CLEANUP_PERIOD: StdDuration = StdDuration::from_secs(60); // timer for cleaning up inactive topics
    const SPDP_PUBLISH_PERIOD: StdDuration = StdDuration::from_secs(10);
    const CHECK_PARTICIPANT_MESSAGES_PERIOD: StdDuration = StdDuration::from_secs(1);

    #[cfg(feature = "security")]
    const CACHED_SECURE_DISCOVERY_MESSAGE_RESEND_PERIOD: StdDuration = StdDuration::from_secs(1);

    fn new() -> Self {
        let participant_cleanup = Timer::new_periodic((), Self::PARTICIPANT_CLEANUP_PERIOD);
        let topic_cleanup = Timer::new_periodic((), Self::TOPIC_CLEANUP_PERIOD);
        let spdp_publish = Timer::new_periodic((), Self::SPDP_PUBLISH_PERIOD);
        let participant_messages = Timer::new_periodic((), Self::CHECK_PARTICIPANT_MESSAGES_PERIOD);

        Self {
            participant_cleanup,
            topic_cleanup,
            spdp_publish,
            participant_messages,
        }
    }

    fn register(mut self, ring: &mut io_uring::IoUring, domain_id: u16) -> std::io::Result<Timers<timer_state::Init>> {
        let Self {
            participant_cleanup,
            topic_cleanup,
            spdp_publish,
            participant_messages,
        } = self;

        use crate::io_uring::encoding::user_data::{Timer, BuiltinTimerVariant};

        let participant_cleanup = participant_cleanup.register(ring, domain_id, Timer::Builtin(BuiltinTimerVariant::ParticipantCleaning))?;
        let topic_cleanup = topic_cleanup.register(ring, domain_id, Timer::Builtin(BuiltinTimerVariant::TopicCleaning))?;
        let spdp_publish = spdp_publish.register(ring, domain_id, Timer::Builtin(BuiltinTimerVariant::SpdpPublish))?;
        let participant_messages = participant_messages.register(ring, domain_id, Timer::Builtin(BuiltinTimerVariant::ParticipantMessages))?;

        Ok(Timers {
            participant_cleanup,
            topic_cleanup,
            spdp_publish,
            participant_messages,
        })
    }
}
use crate::messages::submessages::submessage::WriterSubmessage;

pub struct Discovery2<T> {
  liveliness_state: LivelinessState,

  /*
  dcps_participant: with_key::DiscoveryTopicPlCdr<SpdpDiscoveredParticipantData>,

  // Topic "DCPSSubscription" - announcing and detecting Readers
  dcps_subscription: with_key::DiscoveryTopicPlCdr<DiscoveredReaderData>,

  // Topic "DCPSPublication" - announcing and detecting Writers
  dcps_publication: with_key::DiscoveryTopicPlCdr<DiscoveredWriterData>,

  // Topic "DCPSTopic" - announcing and detecting topics
  dcps_topic: with_key::DiscoveryTopicPlCdr<DiscoveredTopicData>,

  // DCPSParticipantMessage - used by participants to communicate liveness
  dcps_participant_message: with_key::DiscoveryTopicCDR<ParticipantMessageData>,
  */

  // If security is enabled, this field contains a SecureDiscovery struct, an appendix
  // which is used for Secure functionality
  security_opt: Option<SecureDiscovery>,

  timers: Timers<T>,
  pub(crate) caches: Caches,
}

impl Discovery2<timer_state::Uninit> {
    pub fn new(security_plugins_opt: Option<SecurityPluginsHandle>, guid_prefix: GuidPrefix) -> Self {
        #[cfg(not(feature = "security"))]
        let security_opt = security_plugins_opt.and(None); // = None, but avoid warning.
        
        Self {
            timers: Timers::new(),
            liveliness_state: LivelinessState::new(),
            security_opt,
            caches: Caches::new(guid_prefix),
        }
    }

    pub fn register(self, ring: &mut io_uring::IoUring, domain_id: u16) -> std::io::Result<Discovery2<timer_state::Init>> {
        let Self {
            timers,
            liveliness_state,
            security_opt,
            caches,
        } = self;

        let timers = timers.register(ring, domain_id)?;

        Ok(Discovery2 {
            timers,
            liveliness_state,
            security_opt,
            caches,
        })
    }

    /*
  pub fn spdp_receive(&mut self) {
    loop {
      let s = self.dcps_participant.reader.take_next_sample();
      debug!("spdp_receive read {:?}", &s);
      match s {
        Ok(Some(ds)) => {
          #[cfg(not(feature = "security"))]
          let permission = NormalDiscoveryPermission::Allow;

          #[cfg(feature = "security")]
          let permission = if let Some(security) = self.security_opt.as_mut() {
            // Security is enabled. Do a secure read, potentially starting the
            // authentication protocol. The return value tells if normal Discovery is
            // allowed to process the message.
            security.participant_read(
              &ds,
              &self.discovery_db,
              &self.discovery_updated_sender,
              &self.dcps_participant_stateless_message.writer,
            )
          } else {
            // No security configured, always allowed
            NormalDiscoveryPermission::Allow
          };

          if permission == NormalDiscoveryPermission::Allow {
            match ds.value {
              Sample::Value(participant_data) => {
                debug!("spdp_receive discovered {:?}", &participant_data);
                self.process_discovered_participant_data(&participant_data);
              }
              // Sample::Dispose means that DomainParticipant was disposed
              Sample::Dispose(participant_guid) => {
                self.process_participant_dispose(participant_guid.0.prefix);
              }
            }
          }
        }
        Ok(None) => {
          trace!("spdp_receive: no more data");
          return;
        } // no more data
        Err(e) => {
          error!(" !!! spdp_receive: {e:?}");
          return;
        }
      }
    } // loop
  }
  */


}

impl Discovery2<timer_state::Init> {
    pub fn handle_writer_msg<'a, 'b>(&'a mut self, submsg: WriterSubmessage, mr_state: &MessageReceiverState, discovery_db: &'b mut DiscoveryDB, udp_sender: &UDPSender, ring: &mut IoUring) -> Option<DiscoveredKind> {
        use crate::messages::submessages::submessage::HasEntityIds;

        let sender_id = submsg.sender_entity_id();

        if !matches!((submsg.receiver_entity_id(), sender_id), (EntityId::UNKNOWN, EntityId::SEDP_BUILTIN_PUBLICATIONS_WRITER | EntityId::SEDP_BUILTIN_TOPIC_WRITER | EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER | EntityId::SEDP_BUILTIN_SUBSCRIPTIONS_WRITER | EntityId::P2P_BUILTIN_PARTICIPANT_MESSAGE_WRITER)) {
            println!("did not match sender id to builtin");
            return None;
        }

        match submsg {
            WriterSubmessage::Data(data, flags) => {
                use crate::messages::submessages::elements::inline_qos::InlineQos;
                use crate::messages::submessages::submessages::DATA_Flags;
                use crate::WriteOptionsBuilder;
                use crate::dds::ddsdata::DDSData;
                use crate::structure::cache_change::ChangeKind;
                use crate::messages::submessages::elements::serialized_payload::SerializedPayload;

                let receive_timestamp = Timestamp::now();

                // parse write_options out of the message
                let mut write_options_b = WriteOptionsBuilder::new();
                // Check if we have s source timestamp
                if let Some(source_timestamp) = mr_state.source_timestamp {
                  write_options_b = write_options_b.source_timestamp(source_timestamp);
                }
                // Check if the message specifies a related_sample_identity
                let representation_identifier = DATA_Flags::cdr_representation_identifier(flags);
                if let Some(related_sample_identity) =
                  data.inline_qos.as_ref().and_then(|inline_qos_parameters| {
                    InlineQos::related_sample_identity(inline_qos_parameters, representation_identifier)
                      .unwrap_or_else(|e| {
                        error!("Deserializing related_sample_identity: {:?}", &e);
                        None
                      })
                  })
                {
                  write_options_b = write_options_b.related_sample_identity(related_sample_identity);
                }

                let writer_guid = GUID::new_with_prefix_and_id(mr_state.source_guid_prefix, data.writer_id);
                let writer_seq_num = data.writer_sn; // for borrow checker

                let dds_data = match (
                  data.serialized_payload,
                  flags.contains(DATA_Flags::Data),
                  flags.contains(DATA_Flags::Key),
                ) {
                  (Some(serialized_payload), true, false) => {
                    // data
                    Ok(DDSData::new(
                      SerializedPayload::from_bytes(&serialized_payload).map_err(|e| format!("{e:?}")).unwrap(),
                    ))
                  }

                  (Some(serialized_payload), false, true) => {
                    // key
                    Ok(DDSData::new_disposed_by_key(

                        match data.inline_qos.as_ref().and_then(|inline_qos_parameters| {
                          InlineQos::status_info(inline_qos_parameters, representation_identifier).map_or_else(
                            |e| {
                              error!("Deserializing status_info: {:?}", &e);
                              None
                            },
                            Some,
                          )
                        }) {
                          Some(si) => si.change_kind(), // get from inline QoS
                          // TODO: What if si.change_kind() gives ALIVE ??
                          None => {
                            if false {
                              ChangeKind::NotAliveUnregistered
                            } else {
                              ChangeKind::NotAliveDisposed
                            } // TODO: Is this reasonable default?
                          }
                        },
                      SerializedPayload::from_bytes(&serialized_payload).map_err(|e| format!("{e:?}")).unwrap(),
                    ))
                  }

                  (None, false, false) => {
                    // no data, no key. Maybe there is inline QoS?
                    // At least we should find key hash, or we do not know WTF the writer is talking
                    // about
                    let key_hash = if let Some(h) = data.inline_qos.as_ref().and_then(|inline_qos_parameters| {
                      InlineQos::key_hash(inline_qos_parameters).unwrap_or_else(|e| {
                        error!("Deserializing key_hash: {:?}", &e);
                        None
                      })
                    }) {
                      Ok(h)
                    } else {
                      info!("Received DATA that has no payload and no key_hash inline QoS - discarding");
                      // Note: This case is normal when handling coherent sets.
                      // The coherent set end marker is sent as DATA with no payload and not key, only
                      // Inline QoS.
                      Err("DATA with no contents".to_string())
                    }.unwrap();
                    // now, let's try to determine what is the dispose reason

                    let change_kind = match data.inline_qos.as_ref().and_then(|inline_qos_parameters| {
                      InlineQos::status_info(inline_qos_parameters, representation_identifier).map_or_else(
                        |e| {
                          error!("Deserializing status_info: {:?}", &e);
                          None
                        },
                        Some,
                      )
                    }) {
                      Some(si) => si.change_kind(), // get from inline QoS
                      // TODO: What if si.change_kind() gives ALIVE ??
                      None => {
                        if false {
                          ChangeKind::NotAliveUnregistered
                        } else {
                          ChangeKind::NotAliveDisposed
                        } // TODO: Is this reasonable default?
                      }
                    };
                    /*
                    info!(
                      "status change by Inline QoS: topic={:?} change={:?}",
                      self.topic_name, change_kind
                    );
                    */
                    Ok(DDSData::new_disposed_by_key_hash(change_kind, key_hash))
                  }

                  (Some(_), true, true) => {
                    // payload cannot be both key and data.
                    // RTPS Spec 9.4.5.3.1 Flags in the Submessage Header says
                    // "D=1 and K=1 is an invalid combination in this version of the protocol."
                    warn!("Got DATA that claims to be both data and key - discarding.");
                    Err("Ambiguous data/key received.".to_string())
                  }

                  (Some(_), false, false) => {
                    // data but no data? - this should not be possible
                    warn!("make_cache_change - Flags says no data or key, but got payload!");
                    Err("DATA message has mystery contents".to_string())
                  }
                  (None, true, _) | (None, _, true) => {
                    warn!("make_cache_change - Where is my SerializedPayload?");
                    Err("DATA message contents missing".to_string())
                  }
                };

                let Ok(data) = dds_data else {
                    println!("could not parse data to DDSData");
                    return None;
                };

                use crate::structure::cache_change::CacheChange;
                let cache_change = CacheChange::new(writer_guid, writer_seq_num, write_options_b.build(), data);

                let topic_cache = self.caches.topic_cache_from_entity_id(sender_id);
                topic_cache.add_change(&receive_timestamp, cache_change);

                use crate::io_uring::discovery::discovery::Reliability;

                let is_reliable = matches!(
                  topic_cache.topic_qos.reliability(),
                  Some(Reliability::Reliable { .. })
                );

                //1) populate changes to datasample_cache
                self.caches.populate_changes(sender_id, is_reliable);
                //2) handle unread changes from the datasample_cache and bring them back here.

                if matches!(sender_id, EntityId::SPDP_BUILTIN_PARTICIPANT_WRITER) {
                    //TODO: send spdp_liveness for the given guid prefix
                }

                return self.caches.distribute_changes(sender_id, discovery_db);
            }
            WriterSubmessage::Heartbeat(heartbeat, flags) => {
                let writer_guid = GUID::new_with_prefix_and_id(mr_state.source_guid_prefix, heartbeat.writer_id);
                use crate::messages::submessages::submessages::HEARTBEAT_Flags;

                self.caches.handle_heartbeat_msg(writer_guid, &heartbeat, flags.contains(HEARTBEAT_Flags::Final), mr_state, udp_sender, ring);
            }
            //_ => (),
            o => println!("\nother missed {o:?}"),
        }
        None
    }

    fn participant_cleanup(&mut self, discovery_db: &mut DiscoveryDB) -> Vec<(GuidPrefix, LostReason)> {
        self.timers.participant_cleanup.reset();
        discovery_db.participant_cleanup()
    }

    fn spdp_publish(&mut self, participant_guid: GUID) {
        self.timers.spdp_publish.reset();

        let data = SpdpDiscoveredParticipantData::from_local(
            participant_guid,
            Default::default(),
            Default::default(),
            Default::default(),
            Default::default(),
            Default::default(),
            &self.security_opt,
            5.0 * Duration::from(Timers::SPDP_PUBLISH_PERIOD),
        );

        //TODO: writers and locators.

        // writers can probably be constructed here similar to how reading was done (inlined)



        todo!()
        /*
        self
          .dcps_participant
          .writer
          .write(data, None)
          .unwrap_or_else(|e| {
            error!("Discovery: Publishing to DCPS participant topic failed: {e:?}");
          });
        */
    }

    fn topic_cleanup(&mut self, discovery_db: &mut DiscoveryDB) {
        self.timers.topic_cleanup.reset();
        discovery_db.topic_cleanup();
    }

    fn publish_participant_message(&mut self, discovery_db: &DiscoveryDB, guid_prefix: GuidPrefix) {
        self.timers.participant_messages.reset();

        let min_automatic_lease_duration = discovery_db.get_all_local_topic_writers().into_iter().filter_map(|writer| {
            match writer.publication_topic_data.liveliness? {
                Liveliness::Automatic { lease_duration } => Some(lease_duration),
                _ => None,
            }
        }).min();

        let timenow = Timestamp::now();

        let mut messages_to_be_sent = vec![];

        if let Some(min_auto_duration) = min_automatic_lease_duration {
          let time_since_last_auto_update =
            timenow.duration_since(self.liveliness_state.last_auto_update);
          trace!(
            "time_since_last_auto_update: {time_since_last_auto_update:?}, min_auto_duration \
             {min_auto_duration:?}"
          );

          // We choose to send a new liveliness message if longer than half of the min
          // auto duration has elapsed since last message
          if time_since_last_auto_update > min_auto_duration / 2 {
            let msg = ParticipantMessageData {
              guid: guid_prefix,
              kind: ParticipantMessageDataKind::AUTOMATIC_LIVELINESS_UPDATE,
              data: Vec::new(),
            };
            messages_to_be_sent.push(msg);
          }
        }

        if self
          .liveliness_state
          .manual_participant_liveness_refresh_requested
        {
          let msg = ParticipantMessageData {
            guid: guid_prefix,
            kind: ParticipantMessageDataKind::MANUAL_LIVELINESS_UPDATE,
            data: Vec::new(),
          };
          messages_to_be_sent.push(msg);
        }
        
        //TODO: create datawriters for each of the 4 builtin topics
        // create rtps writers for those data writers
        //
        // add timers for bultin readers/writers

        todo!()
        /*
        for msg in messages_to_be_sent {
          let msg_kind = msg.kind;

          //#[cfg(not(feature = "security"))]
          // TODO: add writer to this.
          let write_result = self.dcps_participant_message.writer.write(msg, None);

          /*
          #[cfg(feature = "security")]
          let write_result = if let Some(security) = self.security_opt.as_ref() {
            security.write_liveness_message(
              &self.dcps_participant_message_secure.writer,
              &self.dcps_participant_message.writer,
              msg,
            )
          } else {
            // No security enabled
            self.dcps_participant_message.writer.write(msg, None)
          };
          */

          match write_result {
            Ok(_) => {
              match msg_kind {
                ParticipantMessageDataKind::AUTOMATIC_LIVELINESS_UPDATE => {
                  self.liveliness_state.last_auto_update = timenow;
                }
                ParticipantMessageDataKind::MANUAL_LIVELINESS_UPDATE => {
                  // We delivered what was requested
                  self
                    .liveliness_state
                    .manual_participant_liveness_refresh_requested = false;
                }
                _ => (),
              }
            }
            Err(e) => {
              error!("Failed to writer ParticipantMessageData. {e:?}");
            }
          }
        }
        */
    }
}


// -----------------------------------------------------------------------
// -----------------------------------------------------------------------
// -----------------------------------------------------------------------
// -----------------------------------------------------------------------

/*
#[cfg(test)]
mod tests {
  use std::net::SocketAddr;

  use chrono::Utc;
  use speedy::{Endianness, Writable};
  use mio_06::Token;

  use super::*;
  use crate::{
    dds::adapters::no_key::DeserializerAdapter,
    discovery::sedp_messages::TopicBuiltinTopicData,
    messages::submessages::submessages::{InterpreterSubmessage, WriterSubmessage},
    network::{constant::*, udp_listener::UDPListener, udp_sender::UDPSender},
    rtps::submessage::*,
    test::{
      shape_type::ShapeType,
      test_data::{
        create_cdr_pl_rtps_data_message, spdp_participant_msg_mod, spdp_publication_msg,
        spdp_subscription_msg,
      },
    },
    RepresentationIdentifier,
  };

  #[test]
  fn discovery_participant_data_test() {
    let poll = Poll::new().unwrap();
    const LISTENER_PORT: u16 = spdp_well_known_unicast_port(12, 0);

    let mut udp_listener =
      UDPListener::new_unicast("127.0.0.1", LISTENER_PORT).expect("udp listener creation");
    poll
      .register(
        udp_listener.mio_socket(),
        Token(0),
        Ready::readable(),
        PollOpt::edge(),
      )
      .unwrap();

    // sending participant data to discovery
    let udp_sender = UDPSender::new_with_random_port().expect("failed to create UDPSender");
    let addresses = vec![SocketAddr::new("127.0.0.1".parse().unwrap(), LISTENER_PORT)];

    let tdata = spdp_participant_msg_mod(11000);
    let msg_data = tdata
      .write_to_vec_with_ctx(Endianness::LittleEndian)
      .expect("Failed to write msg data");

    udp_sender.send_to_all(&msg_data, &addresses);

    let mut events = Events::with_capacity(10);
    poll
      .poll(&mut events, Some(StdDuration::from_secs(1)))
      .unwrap();

    let _data2 = udp_listener.get_message();
    // TODO: we should have received our own participants info decoding the
    // actual message might be good idea
  }

  #[test]
  fn discovery_reader_data_test() {
    use crate::{
      serialization::pl_cdr_adapters::PlCdrSerialize, structure::locator::Locator, TopicKind,
    };

    let participant = DomainParticipant::new(0).expect("participant creation");

    let topic = participant
      .create_topic(
        "Square".to_string(),
        "ShapeType".to_string(),
        &QosPolicies::qos_none(),
        TopicKind::WithKey,
      )
      .unwrap();

    let publisher = participant
      .create_publisher(&QosPolicies::qos_none())
      .unwrap();
    let _writer = publisher
      .create_datawriter_cdr::<ShapeType>(&topic, None)
      .unwrap();

    let subscriber = participant
      .create_subscriber(&QosPolicies::qos_none())
      .unwrap();
    let _reader =
      subscriber.create_datareader::<ShapeType, CDRDeserializerAdapter<ShapeType>>(&topic, None);

    let poll: Poll = Poll::new().unwrap();
    const LISTENER_PORT: u16 = spdp_well_known_unicast_port(14, 0);

    let mut udp_listener = UDPListener::new_unicast("127.0.0.1", LISTENER_PORT).unwrap();
    poll
      .register(
        udp_listener.mio_socket(),
        Token(0),
        Ready::readable(),
        PollOpt::edge(),
      )
      .unwrap();

    let udp_sender: UDPSender =
      UDPSender::new_with_random_port().expect("failed to create UDPSender");
    let addresses: Vec<SocketAddr> =
      vec![SocketAddr::new("127.0.0.1".parse().unwrap(), LISTENER_PORT)];

    let mut tdata: crate::rtps::Message = spdp_subscription_msg();
    let mut data: bytes::Bytes;
    for submsg in &mut tdata.submessages {
      match &mut submsg.body {
        SubmessageBody::Writer(WriterSubmessage::Data(d, _)) => {
          let mut drd: DiscoveredReaderData = PlCdrDeserializerAdapter::from_bytes(
            &d.unwrap_serialized_payload_value(),
            RepresentationIdentifier::PL_CDR_LE,
          )
          .unwrap();
          drd.reader_proxy.unicast_locator_list.clear();
          drd
            .reader_proxy
            .unicast_locator_list
            .push(Locator::from(SocketAddr::new(
              "127.0.0.1".parse().unwrap(),
              11001,
            )));
          drd.reader_proxy.multicast_locator_list.clear();

          data = drd
            .to_pl_cdr_bytes(RepresentationIdentifier::PL_CDR_LE)
            .unwrap();
          d.update_serialized_payload_value(data.clone());
        }
        SubmessageBody::Interpreter(_) => (),
        _ => continue,
      }
    }

    let msg_data: Vec<u8> = tdata
      .write_to_vec_with_ctx(Endianness::LittleEndian)
      .expect("Failed to write msg data");

    udp_sender.send_to_all(&msg_data, &addresses);

    let mut events: Events = Events::with_capacity(10);
    poll
      .poll(&mut events, Some(StdDuration::from_secs(1)))
      .unwrap();

    let _data2: Vec<u8> = udp_listener.get_message();
  }

  #[test]
  fn discovery_writer_data_test() {
    use crate::TopicKind;
    let participant = DomainParticipant::new(0).expect("Failed to create participant");

    let topic = participant
      .create_topic(
        "Square".to_string(),
        "ShapeType".to_string(),
        &QosPolicies::qos_none(),
        TopicKind::WithKey,
      )
      .unwrap();

    let publisher = participant
      .create_publisher(&QosPolicies::qos_none())
      .unwrap();
    let _writer = publisher
      .create_datawriter_cdr::<ShapeType>(&topic, None)
      .unwrap();

    let subscriber = participant
      .create_subscriber(&QosPolicies::qos_none())
      .unwrap();
    let _reader =
      subscriber.create_datareader::<ShapeType, CDRDeserializerAdapter<ShapeType>>(&topic, None);

    let poll = Poll::new().unwrap();
    let mut udp_listener = UDPListener::new_unicast("127.0.0.1", 0).unwrap();
    poll
      .register(
        udp_listener.mio_socket(),
        Token(0),
        Ready::readable(),
        PollOpt::edge(),
      )
      .unwrap();

    let udp_sender = UDPSender::new_with_random_port().expect("failed to create UDPSender");
    let addresses = vec![SocketAddr::new(
      "127.0.0.1".parse().unwrap(),
      spdp_well_known_unicast_port(15, 0),
    )];

    let mut tdata = spdp_publication_msg();
    for submsg in &mut tdata.submessages {
      match &mut submsg.body {
        SubmessageBody::Interpreter(v) => match v {
          InterpreterSubmessage::InfoDestination(dst, _flags) => {
            dst.guid_prefix = participant.guid_prefix();
          }
          _ => continue,
        },
        SubmessageBody::Writer(_) => (),
        SubmessageBody::Reader(_) => (),
        #[cfg(feature = "security")]
        SubmessageBody::Security(_) => (),
      }
    }

    let par_msg_data = spdp_participant_msg_mod(udp_listener.port())
      .write_to_vec_with_ctx(Endianness::LittleEndian)
      .expect("Failed to write participant data.");

    let msg_data = tdata
      .write_to_vec_with_ctx(Endianness::LittleEndian)
      .expect("Failed to write msg data");

    udp_sender.send_to_all(&par_msg_data, &addresses);
    udp_sender.send_to_all(&msg_data, &addresses);

    let mut events = Events::with_capacity(10);
    poll
      .poll(&mut events, Some(StdDuration::from_secs(1)))
      .unwrap();

    for _ in udp_listener.messages() {
      info!("Message received");
    }
  }

  #[test]
  fn discovery_topic_data_test() {
    let _participant = DomainParticipant::new(0);

    let topic_data = DiscoveredTopicData::new(
      Utc::now(),
      TopicBuiltinTopicData {
        key: None,
        name: String::from("Square"),
        type_name: String::from("ShapeType"),
        durability: None,
        deadline: None,
        latency_budget: None,
        liveliness: None,
        reliability: None,
        lifespan: None,
        destination_order: None,
        presentation: None,
        history: None,
        resource_limits: None,
        ownership: None,
      },
    );

    let rtps_message = create_cdr_pl_rtps_data_message(
      &topic_data,
      EntityId::SEDP_BUILTIN_TOPIC_READER,
      EntityId::SEDP_BUILTIN_TOPIC_WRITER,
    );

    let udp_sender = UDPSender::new_with_random_port().expect("failed to create UDPSender");
    let addresses = vec![SocketAddr::new(
      "127.0.0.1".parse().unwrap(),
      spdp_well_known_unicast_port(16, 0),
    )];

    let rr = rtps_message
      .write_to_vec_with_ctx(Endianness::LittleEndian)
      .unwrap();

    udp_sender.send_to_all(&rr, &addresses);
  }
}
*/

